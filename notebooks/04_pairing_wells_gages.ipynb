{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Buffer1",
   "id": "5ce5c73e96b46d31"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-13T05:46:53.472752Z",
     "start_time": "2025-08-13T05:46:53.211737Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:50:05.152494Z",
     "start_time": "2025-08-13T05:49:58.717686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merged_data=pd.read_csv('../data/processed/well_pchip.csv')\n",
    "gage_to_wells_df = pd.read_csv('../data/processed/wells_with_catchment_info.csv')"
   ],
   "id": "3ced3e6889c9e995",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:50:35.482826Z",
     "start_time": "2025-08-13T05:50:35.470431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming gage_to_wells_df is already loaded\n",
    "# Convert all column names to lowercase\n",
    "gage_to_wells_df.columns = gage_to_wells_df.columns.str.lower()\n",
    "\n",
    "# Drop the specified columns\n",
    "gage_to_wells_df.drop(columns=['name', 'river', 'state', 'aquifer_na'], inplace=True, errors='ignore')\n",
    "\n",
    "# Rename the specified columns\n",
    "gage_to_wells_df.rename(columns={\n",
    "    'latitude': 'gage_lat',\n",
    "    'longitude': 'gage_lon',\n",
    "    'lat_dec': 'well_lat',\n",
    "    'long_dec': 'well_lon'\n",
    "}, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(gage_to_wells_df.head())\n"
   ],
   "id": "1c7f2eb9c56f7013",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        well_id          well_name   well_lat    well_lon     gse  \\\n",
      "0  3.946181e+14  (D-12- 4)16ccb- 1  39.771627 -111.488248  5980.0   \n",
      "1  3.946341e+14  (D-12- 4)16bcc- 1  39.776071 -111.488248  5960.0   \n",
      "2  3.946431e+14  (D-12- 4)16bcb- 1  39.778571 -111.487970  5955.0   \n",
      "3  3.946491e+14  (D-12- 4)17abd- 1  39.780238 -111.494915  5938.0   \n",
      "4  3.947461e+14  (D-12- 4) 9bab- 1  39.796071 -111.482970  5977.0   \n",
      "\n",
      "                           geometry  catchment_id     gage_id  \\\n",
      "0   POINT (-111.4882484 39.7716267)   710648999.0  10152000.0   \n",
      "1   POINT (-111.4882483 39.7760711)   710647014.0  10152000.0   \n",
      "2  POINT (-111.4879704 39.77857106)   710647014.0  10152000.0   \n",
      "3  POINT (-111.4949154 39.78023766)   710549798.0  10152000.0   \n",
      "4  POINT (-111.4829697 39.79607075)   710647014.0  10152000.0   \n",
      "\n",
      "                             gage_name  \n",
      "0  SPANISH FORK NEAR LAKE SHORE - UTAH  \n",
      "1  SPANISH FORK NEAR LAKE SHORE - UTAH  \n",
      "2  SPANISH FORK NEAR LAKE SHORE - UTAH  \n",
      "3  SPANISH FORK NEAR LAKE SHORE - UTAH  \n",
      "4  SPANISH FORK NEAR LAKE SHORE - UTAH  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:50:48.708241Z",
     "start_time": "2025-08-13T05:50:48.484420Z"
    }
   },
   "cell_type": "code",
   "source": "well_pchip=merged_data.copy()",
   "id": "e65a5ea243e3e0d8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:51:29.437958Z",
     "start_time": "2025-08-13T05:51:28.739097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming well_pchip and gage_to_wells_df are already loaded\n",
    "# Perform an inner merge to filter and combine the data based on 'well_id'\n",
    "filtered_data = pd.merge(\n",
    "    well_pchip,\n",
    "    gage_to_wells_df[['gage_id', 'well_id', 'well_lat', 'well_lon']],\n",
    "    on='well_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Drop the duplicate columns with suffixes\n",
    "filtered_data.drop(columns=['well_lat_x', 'well_lon_x'], inplace=True)\n",
    "\n",
    "# Optionally, rename the remaining columns if needed\n",
    "filtered_data.rename(columns={'well_lat_y': 'well_lat', 'well_lon_y': 'well_lon'}, inplace=True)\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(filtered_data.head())\n"
   ],
   "id": "8557f1e8cf491718",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           well_id        date          wte     gse     gage_id   well_lat  \\\n",
      "0  394643111291401  1971-09-15  5953.300000  5955.0  10152000.0  39.778571   \n",
      "1  394643111291401  1971-09-16  5953.312390  5955.0  10152000.0  39.778571   \n",
      "2  394643111291401  1971-09-17  5953.324794  5955.0  10152000.0  39.778571   \n",
      "3  394643111291401  1971-09-18  5953.337211  5955.0  10152000.0  39.778571   \n",
      "4  394643111291401  1971-09-19  5953.349641  5955.0  10152000.0  39.778571   \n",
      "\n",
      "    well_lon  \n",
      "0 -111.48797  \n",
      "1 -111.48797  \n",
      "2 -111.48797  \n",
      "3 -111.48797  \n",
      "4 -111.48797  \n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:53:16.936965Z",
     "start_time": "2025-08-13T05:53:16.921296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gage_info = pd.read_csv('../data/raw/streamflow/gsl_nwm_gage.csv')\n",
    "gage_info"
   ],
   "id": "2d1303bfbf6ea762",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          id                                               name  \\\n",
       "0   10011200  WEST FORK BEAR RIVER AT WHITNEY DAM - NR OAKLE...   \n",
       "1   10011500            BEAR RIVER NEAR UTAH-WYOMING STATE LINE   \n",
       "2   10015700  SULPHUR CR.AB.RES.BL.LA CHAPELLE CR.NR EVANSTO...   \n",
       "3   10015900       SULPHUR CREEK BL RES. - NEAR EVANSTON - WYO.   \n",
       "4   10016900                        BEAR RIVER AT EVANSTON - WY   \n",
       "..       ...                                                ...   \n",
       "73  10168500           BIG COTTONWOOD CR NR SALT LAKE CITY UTAH   \n",
       "74  10171000    JORDAN RIVER @ 1700 SOUTH @ SALT LAKE CITY - UT   \n",
       "75  10172700                      VERNON CREEK NEAR VERNON - UT   \n",
       "76  10172860                         WARM CREEK NEAR GANDY - UT   \n",
       "77  10172952                   DUNN CREEK NEAR PARK VALLEY - UT   \n",
       "\n",
       "                      River   latitude   longitude  elevation_m    state  \n",
       "0      WEST FORK BEAR RIVER  40.841614 -110.927119         2797     Utah  \n",
       "1                BEAR RIVER  40.965225 -110.853508         2432     Utah  \n",
       "2             SULPHUR CREEK  41.129114 -110.806563         2205  Wyoming  \n",
       "3             SULPHUR CREEK  41.156058 -110.835176         2173  Wyoming  \n",
       "4                BEAR RIVER  41.270224 -110.963793         2057  Wyoming  \n",
       "..                      ...        ...         ...          ...      ...  \n",
       "73  LITTLE COTTONWOOD CREEK  40.618559 -111.781876         1527     Utah  \n",
       "74             JORDAN RIVER  40.733557 -111.923270         1294     Utah  \n",
       "75             VERNON CREEK  39.979391 -112.380230         1898     Utah  \n",
       "76               WARM CREEK  39.459528 -114.023722         1573     Utah  \n",
       "77               DUNN CREEK  41.858530 -113.327219         1910     Utah  \n",
       "\n",
       "[78 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>River</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation_m</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10011200</td>\n",
       "      <td>WEST FORK BEAR RIVER AT WHITNEY DAM - NR OAKLE...</td>\n",
       "      <td>WEST FORK BEAR RIVER</td>\n",
       "      <td>40.841614</td>\n",
       "      <td>-110.927119</td>\n",
       "      <td>2797</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10011500</td>\n",
       "      <td>BEAR RIVER NEAR UTAH-WYOMING STATE LINE</td>\n",
       "      <td>BEAR RIVER</td>\n",
       "      <td>40.965225</td>\n",
       "      <td>-110.853508</td>\n",
       "      <td>2432</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10015700</td>\n",
       "      <td>SULPHUR CR.AB.RES.BL.LA CHAPELLE CR.NR EVANSTO...</td>\n",
       "      <td>SULPHUR CREEK</td>\n",
       "      <td>41.129114</td>\n",
       "      <td>-110.806563</td>\n",
       "      <td>2205</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10015900</td>\n",
       "      <td>SULPHUR CREEK BL RES. - NEAR EVANSTON - WYO.</td>\n",
       "      <td>SULPHUR CREEK</td>\n",
       "      <td>41.156058</td>\n",
       "      <td>-110.835176</td>\n",
       "      <td>2173</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10016900</td>\n",
       "      <td>BEAR RIVER AT EVANSTON - WY</td>\n",
       "      <td>BEAR RIVER</td>\n",
       "      <td>41.270224</td>\n",
       "      <td>-110.963793</td>\n",
       "      <td>2057</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>10168500</td>\n",
       "      <td>BIG COTTONWOOD CR NR SALT LAKE CITY UTAH</td>\n",
       "      <td>LITTLE COTTONWOOD CREEK</td>\n",
       "      <td>40.618559</td>\n",
       "      <td>-111.781876</td>\n",
       "      <td>1527</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>10171000</td>\n",
       "      <td>JORDAN RIVER @ 1700 SOUTH @ SALT LAKE CITY - UT</td>\n",
       "      <td>JORDAN RIVER</td>\n",
       "      <td>40.733557</td>\n",
       "      <td>-111.923270</td>\n",
       "      <td>1294</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>10172700</td>\n",
       "      <td>VERNON CREEK NEAR VERNON - UT</td>\n",
       "      <td>VERNON CREEK</td>\n",
       "      <td>39.979391</td>\n",
       "      <td>-112.380230</td>\n",
       "      <td>1898</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>10172860</td>\n",
       "      <td>WARM CREEK NEAR GANDY - UT</td>\n",
       "      <td>WARM CREEK</td>\n",
       "      <td>39.459528</td>\n",
       "      <td>-114.023722</td>\n",
       "      <td>1573</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>10172952</td>\n",
       "      <td>DUNN CREEK NEAR PARK VALLEY - UT</td>\n",
       "      <td>DUNN CREEK</td>\n",
       "      <td>41.858530</td>\n",
       "      <td>-113.327219</td>\n",
       "      <td>1910</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:57:22.103003Z",
     "start_time": "2025-08-13T05:57:21.680491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge gage_info with filtered_data to add gage coordinates\n",
    "filtered_data = pd.merge(\n",
    "    filtered_data,\n",
    "    gage_info[['id', 'latitude', 'longitude']],\n",
    "    left_on='gage_id',\n",
    "    right_on='id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Rename the columns\n",
    "filtered_data.rename(columns={\n",
    "    'latitude': 'gage_lat',\n",
    "    'longitude': 'gage_lon'\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop the redundant id column\n",
    "filtered_data.drop('id', axis=1, inplace=True)\n"
   ],
   "id": "c722fd287eb584f2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:57:55.325006Z",
     "start_time": "2025-08-13T05:57:38.428133Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_data.to_csv('../data/processed/after_buffer1.csv', index=False)",
   "id": "9336519141fee848",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:58:50.694401Z",
     "start_time": "2025-08-13T05:58:50.648193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the number of unique wells\n",
    "unique_wells_count = filtered_data['well_id'].nunique()\n",
    "\n",
    "# Display the result\n",
    "print(f\"Number of unique wells: {unique_wells_count}\")\n",
    "\n",
    "unique_gages_count = filtered_data['gage_id'].nunique()\n",
    "print(f\"Number of unique gages: {unique_gages_count}\")"
   ],
   "id": "966595cff17fec2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique wells: 635\n",
      "Number of unique gages: 7\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# buffer2",
   "id": "e8c60dac38f6bb58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T06:52:48.582107Z",
     "start_time": "2025-08-13T06:52:48.053738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def filter_and_analyze_wte(filtered_data, merged_df, distance_buffer_meters=30, delta_bins=None):\n",
    "    # Convert WTE from feet to meters\n",
    "    filtered_data['wte_meters'] = filtered_data['wte'] * 0.3048\n",
    "\n",
    "    # Merge filtered_data with merged_df to get reach_elev\n",
    "    merged_data = pd.merge(\n",
    "        filtered_data,\n",
    "        merged_df[['well_id', 'reach_elev_m']],\n",
    "        on='well_id',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    # Calculate the difference between reach elevation and WTE\n",
    "    merged_data['delta_elev'] = merged_data['reach_elev_m'] - merged_data['wte_meters']\n",
    "\n",
    "    # Filter out values where the difference is greater than the distance buffer\n",
    "    filtered_result = merged_data[merged_data['delta_elev'] <= distance_buffer_meters]\n",
    "\n",
    "    # Define default delta bins if not provided\n",
    "    if delta_bins is None:\n",
    "        delta_bins = [-float('inf'), -20, -10, -5, 0, 5, 10, 20, 30, 50, 75, 100, float('inf')]\n",
    "\n",
    "    # Bin the delta_elev values\n",
    "    bin_labels = [f\"< {delta_bins[1]}\"] + \\\n",
    "                 [f\"{delta_bins[i]} to {delta_bins[i+1]}\" for i in range(1, len(delta_bins)-2)] + \\\n",
    "                 [f\">= {delta_bins[-2]}\"]\n",
    "    filtered_result['delta_bin'] = pd.cut(filtered_result['delta_elev'], bins=delta_bins, labels=bin_labels)\n",
    "\n",
    "    # Calculate statistics\n",
    "    total_measurements = len(filtered_result)\n",
    "    dist_stats = filtered_result.groupby('delta_bin').size().reset_index(name='count')\n",
    "    dist_stats['percentage'] = (dist_stats['count'] / total_measurements * 100).round(2)\n",
    "\n",
    "    # Display statistics\n",
    "    print(dist_stats)\n",
    "\n",
    "    return filtered_result, dist_stats\n",
    "\n",
    "# Example usage\n",
    "filtered_data = pd.read_csv('../data/processed/after_buffer1.csv')  # Load your filtered data\n",
    "merged_df = pd.read_csv('../data/processed/well_reach.csv')  # Load the merged data with reach_elev\n",
    "# filtered_result, dist_stats = filter_and_analyze_wte(filtered_data, merged_df, distance_buffer_meters=30)\n"
   ],
   "id": "cb2f0c0f57445e6b",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T06:52:50.303761Z",
     "start_time": "2025-08-13T06:52:50.261324Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_result, dist_stats = filter_and_analyze_wte(filtered_data, merged_df, distance_buffer_meters=10000)",
   "id": "3a68bd7b7aaa52db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     delta_bin  count  percentage\n",
      "0        < -20      0         NaN\n",
      "1   -20 to -10      0         NaN\n",
      "2    -10 to -5      0         NaN\n",
      "3      -5 to 0      0         NaN\n",
      "4       0 to 5      0         NaN\n",
      "5      5 to 10      0         NaN\n",
      "6     10 to 20      0         NaN\n",
      "7     20 to 30      0         NaN\n",
      "8     30 to 50      0         NaN\n",
      "9     50 to 75      0         NaN\n",
      "10   75 to 100      0         NaN\n",
      "11      >= 100      0         NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_13546/3223962800.py:34: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  dist_stats = filtered_result.groupby('delta_bin').size().reset_index(name='count')\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T06:20:27.937079Z",
     "start_time": "2025-08-13T06:20:27.929560Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_result",
   "id": "85186d4690435b72",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [well_id, date, wte, gse, gage_id, well_lat, well_lon, gage_lat, gage_lon, wte_meters, reach_elev_m, delta_elev, delta_bin]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well_id</th>\n",
       "      <th>date</th>\n",
       "      <th>wte</th>\n",
       "      <th>gse</th>\n",
       "      <th>gage_id</th>\n",
       "      <th>well_lat</th>\n",
       "      <th>well_lon</th>\n",
       "      <th>gage_lat</th>\n",
       "      <th>gage_lon</th>\n",
       "      <th>wte_meters</th>\n",
       "      <th>reach_elev_m</th>\n",
       "      <th>delta_elev</th>\n",
       "      <th>delta_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "filtered_result.to_csv('../data/processed/after_buffer2_30m.csv', index=False)",
   "id": "caa0673414248331"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## use q dates to filter after buffer2",
   "id": "94b10dfb318f1b8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:11:33.787509Z",
     "start_time": "2025-08-13T17:11:33.778552Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_data.head()",
   "id": "4e0aecb30d2d7fe1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        well_id     date          wte     gse   gage_id   well_lat   well_lon  \\\n",
       "0  3.946430e+14  9/15/71  5953.300000  5955.0  10152000  39.778571 -111.48797   \n",
       "1  3.946430e+14  9/16/71  5953.312390  5955.0  10152000  39.778571 -111.48797   \n",
       "2  3.946430e+14  9/17/71  5953.324794  5955.0  10152000  39.778571 -111.48797   \n",
       "3  3.946430e+14  9/18/71  5953.337211  5955.0  10152000  39.778571 -111.48797   \n",
       "4  3.946430e+14  9/19/71  5953.349641  5955.0  10152000  39.778571 -111.48797   \n",
       "\n",
       "    gage_lat    gage_lon   wte_meters  \n",
       "0  40.150232 -111.726039  1814.565840  \n",
       "1  40.150232 -111.726039  1814.569616  \n",
       "2  40.150232 -111.726039  1814.573397  \n",
       "3  40.150232 -111.726039  1814.577182  \n",
       "4  40.150232 -111.726039  1814.580971  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well_id</th>\n",
       "      <th>date</th>\n",
       "      <th>wte</th>\n",
       "      <th>gse</th>\n",
       "      <th>gage_id</th>\n",
       "      <th>well_lat</th>\n",
       "      <th>well_lon</th>\n",
       "      <th>gage_lat</th>\n",
       "      <th>gage_lon</th>\n",
       "      <th>wte_meters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.946430e+14</td>\n",
       "      <td>9/15/71</td>\n",
       "      <td>5953.300000</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>10152000</td>\n",
       "      <td>39.778571</td>\n",
       "      <td>-111.48797</td>\n",
       "      <td>40.150232</td>\n",
       "      <td>-111.726039</td>\n",
       "      <td>1814.565840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.946430e+14</td>\n",
       "      <td>9/16/71</td>\n",
       "      <td>5953.312390</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>10152000</td>\n",
       "      <td>39.778571</td>\n",
       "      <td>-111.48797</td>\n",
       "      <td>40.150232</td>\n",
       "      <td>-111.726039</td>\n",
       "      <td>1814.569616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.946430e+14</td>\n",
       "      <td>9/17/71</td>\n",
       "      <td>5953.324794</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>10152000</td>\n",
       "      <td>39.778571</td>\n",
       "      <td>-111.48797</td>\n",
       "      <td>40.150232</td>\n",
       "      <td>-111.726039</td>\n",
       "      <td>1814.573397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.946430e+14</td>\n",
       "      <td>9/18/71</td>\n",
       "      <td>5953.337211</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>10152000</td>\n",
       "      <td>39.778571</td>\n",
       "      <td>-111.48797</td>\n",
       "      <td>40.150232</td>\n",
       "      <td>-111.726039</td>\n",
       "      <td>1814.577182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.946430e+14</td>\n",
       "      <td>9/19/71</td>\n",
       "      <td>5953.349641</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>10152000</td>\n",
       "      <td>39.778571</td>\n",
       "      <td>-111.48797</td>\n",
       "      <td>40.150232</td>\n",
       "      <td>-111.726039</td>\n",
       "      <td>1814.580971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:11:36.916818Z",
     "start_time": "2025-08-13T17:11:36.891797Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_result = filtered_data.copy()",
   "id": "5865e1fb586c291b",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:11:55.440241Z",
     "start_time": "2025-08-13T17:11:55.393693Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_result.info()\n",
   "id": "5eec9e3f80031c8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count    Dtype  \n",
      "---  ------      --------------    -----  \n",
      " 0   well_id     1048575 non-null  float64\n",
      " 1   date        1048575 non-null  object \n",
      " 2   wte         1048575 non-null  float64\n",
      " 3   gse         1048575 non-null  float64\n",
      " 4   gage_id     1048575 non-null  int64  \n",
      " 5   well_lat    1048575 non-null  float64\n",
      " 6   well_lon    1048575 non-null  float64\n",
      " 7   gage_lat    1048575 non-null  float64\n",
      " 8   gage_lon    1048575 non-null  float64\n",
      " 9   wte_meters  1048575 non-null  float64\n",
      "dtypes: float64(8), int64(1), object(1)\n",
      "memory usage: 80.0+ MB\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:07:12.316383Z",
     "start_time": "2025-08-13T17:07:12.159457Z"
    }
   },
   "cell_type": "code",
   "source": "compiled_data=pd.read_csv('../data/processed/streamflow/q_bfd_1.csv')",
   "id": "aa9eee51d51dbd14",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:12:13.795698Z",
     "start_time": "2025-08-13T17:12:13.788675Z"
    }
   },
   "cell_type": "code",
   "source": "compiled_data.head()",
   "id": "ddee2a3ec6bf6e91",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    gage_id        date    q  bfd\n",
       "0  10015900  1958-04-01  0.0  1.0\n",
       "1  10015900  1958-04-02  0.0  1.0\n",
       "2  10015900  1958-04-03  0.0  1.0\n",
       "3  10015900  1958-04-04  0.0  1.0\n",
       "4  10015900  1958-04-05  0.0  1.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gage_id</th>\n",
       "      <th>date</th>\n",
       "      <th>q</th>\n",
       "      <th>bfd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:21:46.567255Z",
     "start_time": "2025-08-13T17:21:32.058879Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd\n\n# 首先检查日期格式\nprint(\"=== 日期格式检查 ===\")\nprint(\"filtered_result date samples:\")\nprint(filtered_result['date'].head())\nprint(\"compiled_data date samples:\")\nprint(compiled_data['date'].head())\n\n# 检查日期格式是否一致\nprint(f\"\\nfiltered_result date type: {type(filtered_result['date'].iloc[0])}\")\nprint(f\"compiled_data date type: {type(compiled_data['date'].iloc[0])}\")\n\n# 标准化日期格式\nfiltered_result_copy = filtered_result.copy()\ncompiled_data_copy = compiled_data.copy()\n\n# 转换日期格式\nfiltered_result_copy['date'] = pd.to_datetime(filtered_result_copy['date']).dt.strftime('%Y-%m-%d')\ncompiled_data_copy['date'] = pd.to_datetime(compiled_data_copy['date']).dt.strftime('%Y-%m-%d')\n\n# Ensure both gage_id columns are of the same type\nfiltered_result_copy['gage_id'] = filtered_result_copy['gage_id'].astype(str)\ncompiled_data_copy['gage_id'] = compiled_data_copy['gage_id'].astype(str)\n\nprint(\"\\n=== 标准化后的日期格式 ===\")\nprint(\"filtered_result date samples:\")\nprint(filtered_result_copy['date'].head())\nprint(\"compiled_data date samples:\")\nprint(compiled_data_copy['date'].head())\n\n# 检查gage_id重合情况\nfiltered_gages = set(filtered_result_copy['gage_id'])\ncompiled_gages = set(compiled_data_copy['gage_id'])\noverlap = filtered_gages.intersection(compiled_gages)\nprint(f\"\\n=== gage_id重合检查 ===\")\nprint(f\"filtered_result中的gage_id: {sorted(list(filtered_gages))}\")\nprint(f\"compiled_data中的gage_id: {sorted(list(compiled_gages))}\")\nprint(f\"重合的gage_id数量: {len(overlap)}\")\nprint(f\"重合的gage_id: {sorted(list(overlap))}\")\n\n# 如果有重合，进行merge\nif len(overlap) > 0:\n    # Perform the merge\n    q_buffer2_pair = pd.merge(\n        filtered_result_copy,\n        compiled_data_copy[['gage_id', 'date','q','bfd']],\n        on=['gage_id', 'date'],\n        how='inner'\n    )\n    print(f\"\\n=== Merge结果 ===\")\n    print(f\"合并后的记录数: {len(q_buffer2_pair)}\")\n    print(\"前5行:\")\n    print(q_buffer2_pair.head())\nelse:\n    print(\"\\n=== 没有重合的gage_id，merge结果为空 ===\")\n    q_buffer2_pair = pd.DataFrame()",
   "id": "f361d42ebea05440",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 日期格式检查 ===\n",
      "filtered_result date samples:\n",
      "0    9/15/71\n",
      "1    9/16/71\n",
      "2    9/17/71\n",
      "3    9/18/71\n",
      "4    9/19/71\n",
      "Name: date, dtype: object\n",
      "compiled_data date samples:\n",
      "0    1958-04-01\n",
      "1    1958-04-02\n",
      "2    1958-04-03\n",
      "3    1958-04-04\n",
      "4    1958-04-05\n",
      "Name: date, dtype: object\n",
      "\n",
      "filtered_result date type: <class 'str'>\n",
      "compiled_data date type: <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_13546/3076181137.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  filtered_result_copy['date'] = pd.to_datetime(filtered_result_copy['date']).dt.strftime('%Y-%m-%d')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 标准化后的日期格式 ===\n",
      "filtered_result date samples:\n",
      "0    2071-09-15\n",
      "1    2071-09-16\n",
      "2    2071-09-17\n",
      "3    2071-09-18\n",
      "4    2071-09-19\n",
      "Name: date, dtype: object\n",
      "compiled_data date samples:\n",
      "0    1958-04-01\n",
      "1    1958-04-02\n",
      "2    1958-04-03\n",
      "3    1958-04-04\n",
      "4    1958-04-05\n",
      "Name: date, dtype: object\n",
      "\n",
      "=== gage_id重合检查 ===\n",
      "filtered_result中的gage_id: ['10141000', '10152000', '10153100', '10163000', '10168000']\n",
      "compiled_data中的gage_id: ['10011500', '10015700', '10015900', '10016900', '10020100', '10020300', '10023000', '10026500', '10028500', '10038000', '10039500', '10041000', '10046500', '10047500', '10058600', '10068500', '10079500', '10092700', '10102250', '10104700', '10104900', '10105900', '10106000', '10109000', '10109001', '10113500', '10118000', '10125500', '10126000', '10128500', '10129300', '10129500', '10129900', '10130500', '10131000', '10132000', '10132500', '10133600', '10133650', '10133800', '10134500', '10136500', '10137500', '10139300', '10140100', '10141000', '10142000', '10143500', '10146000', '10146400', '10150500', '10152000', '10153100', '10153800', '10154200', '10155000', '10155200', '10155500', '10156000', '10157500', '10159500', '10163000', '10164500', '10167000', '10168000', '10168500', '10171000', '10172700', '10172860', '10172952']\n",
      "重合的gage_id数量: 5\n",
      "重合的gage_id: ['10141000', '10152000', '10153100', '10163000', '10168000']\n",
      "\n",
      "=== Merge结果 ===\n",
      "合并后的记录数: 429009\n",
      "前5行:\n",
      "        well_id        date          wte     gse   gage_id   well_lat  \\\n",
      "0  3.946430e+14  1975-01-01  5954.322586  5955.0  10152000  39.778571   \n",
      "1  3.946430e+14  1975-01-02  5954.325175  5955.0  10152000  39.778571   \n",
      "2  3.946430e+14  1975-01-03  5954.327746  5955.0  10152000  39.778571   \n",
      "3  3.946430e+14  1975-01-04  5954.330300  5955.0  10152000  39.778571   \n",
      "4  3.946430e+14  1975-01-05  5954.332834  5955.0  10152000  39.778571   \n",
      "\n",
      "    well_lon   gage_lat    gage_lon   wte_meters     q  bfd  \n",
      "0 -111.48797  40.150232 -111.726039  1814.877524  96.0  1.0  \n",
      "1 -111.48797  40.150232 -111.726039  1814.878313  90.0  1.0  \n",
      "2 -111.48797  40.150232 -111.726039  1814.879097  90.0  1.0  \n",
      "3 -111.48797  40.150232 -111.726039  1814.879875  93.0  1.0  \n",
      "4 -111.48797  40.150232 -111.726039  1814.880648  95.0  1.0  \n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:19:40.887406Z",
     "start_time": "2025-08-13T17:19:40.531876Z"
    }
   },
   "cell_type": "code",
   "source": "# 检查compiled_data中bfd=1的记录数\nprint(\"Number of records with bfd=1:\", len(compiled_data[compiled_data['bfd'] == 1]))\n\n# 检查两个DataFrame中的gage_id范围\nprint(\"\\nGage IDs in filtered_result:\", filtered_result['gage_id'].unique())\nprint(\"Gage IDs in compiled_data:\", compiled_data['gage_id'].unique())\n\n# 检查gage_id是否有重合\nfiltered_gages = set(filtered_result['gage_id'].astype(str))\ncompiled_gages = set(compiled_data['gage_id'].astype(str))\noverlap = filtered_gages.intersection(compiled_gages)\nprint(f\"\\n重合的gage_id数量: {len(overlap)}\")\nprint(f\"重合的gage_id: {list(overlap)}\")\n\n# 检查日期范围\nprint(\"\\nDate range in filtered_result:\",\n      filtered_result['date'].min(), \"to\", filtered_result['date'].max())\nprint(\"Date range in compiled_data:\",\n      compiled_data['date'].min(), \"to\", compiled_data['date'].max())\n\n# 检查数据类型\nprint(\"\\nData types in filtered_result:\")\nprint(filtered_result[['gage_id', 'date']].dtypes)\nprint(\"\\nData types in compiled_data:\")\nprint(compiled_data[['gage_id', 'date']].dtypes)",
   "id": "9c74c0cd9194e497",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with bfd=1: 885716\n",
      "\n",
      "Gage IDs in filtered_result: ['10152000' '10141000' '10153100' '10163000' '10168000']\n",
      "Gage IDs in compiled_data: ['10015900' '10157500' '10134500' '10141000' '10041000' '10026500'\n",
      " '10092700' '10118000' '10106000' '10159500' '10105900' '10047500'\n",
      " '10136500' '10132000' '10028500' '10128500' '10155500' '10167000'\n",
      " '10133650' '10129900' '10171000' '10079500' '10163000' '10153100'\n",
      " '10132500' '10155000' '10143500' '10155200' '10104700' '10020300'\n",
      " '10020100' '10172860' '10133800' '10038000' '10126000' '10130500'\n",
      " '10168000' '10011500' '10131000' '10152000' '10023000' '10039500'\n",
      " '10133600' '10129300' '10172700' '10139300' '10109000' '10113500'\n",
      " '10046500' '10142000' '10104900' '10109001' '10125500' '10016900'\n",
      " '10129500' '10137500' '10172952' '10154200' '10102250' '10150500'\n",
      " '10146000' '10153800' '10140100' '10156000' '10164500' '10068500'\n",
      " '10168500' '10146400' '10015700' '10058600']\n",
      "\n",
      "重合的gage_id数量: 5\n",
      "重合的gage_id: ['10152000', '10141000', '10163000', '10168000', '10153100']\n",
      "\n",
      "Date range in filtered_result: 1/1/00 to 9/9/99\n",
      "Date range in compiled_data: 1902-10-09 to 2025-01-28\n",
      "\n",
      "Data types in filtered_result:\n",
      "gage_id    object\n",
      "date       object\n",
      "dtype: object\n",
      "\n",
      "Data types in compiled_data:\n",
      "gage_id    object\n",
      "date       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:22:14.904267Z",
     "start_time": "2025-08-13T17:22:13.157036Z"
    }
   },
   "cell_type": "code",
   "source": "q_buffer2_pair.to_csv('../data/processed/q_buffer2_pair_test.csv', index=False)",
   "id": "a7a645dcdd7ec556",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:22:05.575872Z",
     "start_time": "2025-08-13T17:22:05.536261Z"
    }
   },
   "cell_type": "code",
   "source": "q_buffer2_pair.info()",
   "id": "fa5374c4e7281bd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 429009 entries, 0 to 429008\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   well_id     429009 non-null  float64\n",
      " 1   date        429009 non-null  object \n",
      " 2   wte         429009 non-null  float64\n",
      " 3   gse         429009 non-null  float64\n",
      " 4   gage_id     429009 non-null  object \n",
      " 5   well_lat    429009 non-null  float64\n",
      " 6   well_lon    429009 non-null  float64\n",
      " 7   gage_lat    429009 non-null  float64\n",
      " 8   gage_lon    429009 non-null  float64\n",
      " 9   wte_meters  429009 non-null  float64\n",
      " 10  q           429009 non-null  float64\n",
      " 11  bfd         429009 non-null  float64\n",
      "dtypes: float64(10), object(2)\n",
      "memory usage: 39.3+ MB\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "47db86b3e05a5e55"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
