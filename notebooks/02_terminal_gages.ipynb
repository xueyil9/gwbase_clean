{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load data",
   "id": "f68db6b15bdeef1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T03:32:07.007212Z",
     "start_time": "2025-08-13T03:32:06.856658Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install rasterio",
   "id": "6d952d1b8d80dc59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\r\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-13T03:30:09.683810Z",
     "start_time": "2025-08-13T03:30:09.679833Z"
    }
   },
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T03:32:50.017631Z",
     "start_time": "2025-08-13T03:32:49.490773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "subbasin_gdf = gpd.read_file('../data/raw/hydrography/gsl_catchment.shp')\n",
    "gage_df = pd.read_csv('../data/raw/hydrography/gsl_nwm_gage.csv')\n",
    "well_gdf = gpd.read_file('../data/raw/hydrography/well_shp.shp')\n",
    "stream_gdf = gpd.read_file('../data/raw/hydrography/gslb_stream.shp')\n",
    "lake_gdf = gpd.read_file('../data/raw/hydrography/lake.shp')"
   ],
   "id": "99a5d14b645b1e03",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# find downstream gage",
   "id": "e50df9308c4f9417"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T03:40:20.044950Z",
     "start_time": "2025-08-13T03:40:20.006695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Convert gage dataframe to GeoDataFrame (to match with subbasin_gdf)\n",
    "# Create point geometries from longitude/latitude coordinates\n",
    "gage_gdf = gpd.GeoDataFrame(\n",
    "    gage_df,\n",
    "    geometry=gpd.points_from_xy(gage_df['longitude'], gage_df['latitude']),\n",
    "    crs=subbasin_gdf.crs\n",
    ")\n",
    "\n",
    "# Spatial join to find which subbasin each gage falls within\n",
    "# Only keep gages that are within a subbasin (inner join)\n",
    "matched_gages = gpd.sjoin(\n",
    "    gage_gdf[['id', 'name', 'geometry']],\n",
    "    subbasin_gdf[['linkno', 'geometry']],\n",
    "    how='inner',\n",
    "    predicate='within'\n",
    ").rename(columns={'linkno': 'catchment_id'})\n",
    "\n",
    "# Keep only relevant columns\n",
    "matched_gages = matched_gages[['id', 'name', 'geometry', 'catchment_id']]\n",
    "\n"
   ],
   "id": "d650dbd8e0a3c38b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T03:40:25.326351Z",
     "start_time": "2025-08-13T03:40:24.899247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a directed graph representing the river network\n",
    "import networkx as nx\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add edges to graph based on stream connectivity\n",
    "# DSLINKNO represents downstream link number\n",
    "for _, row in stream_gdf.iterrows():\n",
    "    if pd.notna(row['DSLINKNO']) and row['DSLINKNO'] > 0:\n",
    "        G.add_edge(int(row['LINKNO']), int(row['DSLINKNO']))\n",
    "\n",
    "# Create dictionary mapping gage IDs to their catchment IDs\n",
    "gage_links = dict(zip(matched_gages['id'], matched_gages['catchment_id']))\n",
    "terminal_ids = []\n",
    "\n",
    "# Find terminal gages (those that don't flow to any other gage)\n",
    "for g1_id, g1_link in gage_links.items():\n",
    "    is_terminal = True\n",
    "    for g2_id, g2_link in gage_links.items():\n",
    "        if g1_id != g2_id:\n",
    "            try:\n",
    "                # If there's a path from g1 to g2, then g1 is not terminal\n",
    "                if nx.has_path(G, g1_link, g2_link):\n",
    "                    is_terminal = False\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "    if is_terminal:\n",
    "        terminal_ids.append(g1_id)"
   ],
   "id": "e04d3765d7426328",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T03:40:28.100359Z",
     "start_time": "2025-08-13T03:40:28.098318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Manual adjustments to terminal gages list based on domain knowledge\n",
    "gages_to_remove = [10171000, 10167000]\n",
    "gages_to_add = [10163000, 10153100, 10152000]"
   ],
   "id": "3edd90485a15ee93",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T03:40:34.430319Z",
     "start_time": "2025-08-13T03:40:31.663574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove specified gages\n",
    "terminal_ids = [gage_id for gage_id in terminal_ids if gage_id not in gages_to_remove]\n",
    "\n",
    "# Add new gages if they exist in matched_gages\n",
    "for gage_id in gages_to_add:\n",
    "    if gage_id in matched_gages['id'].values and gage_id not in terminal_ids:\n",
    "        terminal_ids.append(gage_id)\n",
    "\n",
    "# Create dataframe of terminal gages\n",
    "terminal_gages = matched_gages[matched_gages['id'].isin(terminal_ids)].copy()\n",
    "\n",
    "# Find all upstream catchments for each terminal gage\n",
    "records = []\n",
    "for _, gage in terminal_gages.iterrows():\n",
    "    upstream_ids = set()\n",
    "    # Check each node in the graph\n",
    "    for node in G.nodes:\n",
    "        # If there's a path from node to terminal gage's catchment,\n",
    "        # then this node is upstream\n",
    "        if nx.has_path(G, node, gage['catchment_id']):\n",
    "            upstream_ids.add(node)\n",
    "    # Include the terminal gage's own catchment\n",
    "    upstream_ids.add(gage['catchment_id'])\n",
    "\n",
    "    # Create records for each upstream catchment\n",
    "    for up_id in upstream_ids:\n",
    "        records.append({\n",
    "            'Gage_ID': gage['id'],\n",
    "            'Gage_Name': gage['name'],\n",
    "            'Terminal_Catchment_ID': gage['catchment_id'],\n",
    "            'Upstream_Catchment_ID': up_id\n",
    "        })\n",
    "\n",
    "# Create and save the final dataframe\n",
    "df_upstream = pd.DataFrame(records)\n",
    "df_upstream.to_csv(\"../data/processed/terminal_gage_upstream_catchments.csv\", index=False)"
   ],
   "id": "b15a57b53bf2abd4",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T03:42:45.679231Z",
     "start_time": "2025-08-13T03:42:45.666651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Number of unique gages in df_upstream: {df_upstream[\"Gage_ID\"].nunique()}')\n",
    "print('\\nTerminal gage names:')\n",
    "for _, row in df_upstream[['Gage_ID', 'Gage_Name']].drop_duplicates().iterrows():\n",
    "    print(f'{row[\"Gage_ID\"]}: {row[\"Gage_Name\"]}')\n"
   ],
   "id": "4232d1b2f3713646",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique gages in df_upstream: 12\n",
      "\n",
      "Terminal gage names:\n",
      "10126000: BEAR RIVER NEAR CORINNE - UT\n",
      "10141000: WEBER RIVER NEAR PLAIN CITY - UT\n",
      "10142000: FARMINGTON CR ABV DIV NR FARMINGTON - UTAH\n",
      "10143500: CENTERVILLE CREEK ABV. DIV NEAR CENTERVILLE - UT\n",
      "10152000: SPANISH FORK NEAR LAKE SHORE - UTAH\n",
      "10153100: HOBBLE CREEK AT 1650 WEST AT SPRINGVILLE - UTAH\n",
      "10163000: PROVO RIVER AT PROVO - UT\n",
      "10168000: LITTLE COTTONWOOD CREEK @ JORDAN RIVER NR SLC\n",
      "10168500: BIG COTTONWOOD CR NR SALT LAKE CITY UTAH\n",
      "10172700: VERNON CREEK NEAR VERNON - UT\n",
      "10172860: WARM CREEK NEAR GANDY - UT\n",
      "10172952: DUNN CREEK NEAR PARK VALLEY - UT\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8d33a69f0a22a4f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
