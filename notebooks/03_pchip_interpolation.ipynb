{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Streamflow ML results",
   "id": "3d2b54810f170636"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## filter q (bfd=1)",
   "id": "41a532437f802c78"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-20T05:28:50.897043Z",
     "start_time": "2025-08-20T05:28:49.970631Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# from main_jupyter import final_measurements_delta\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "directory = '../data/raw/streamflow/GSLB_ML'\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "compiled_data = pd.DataFrame(columns=['gage_id', 'date', 'q', 'bfd'])\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Filter rows where ML_BFD is 1\n",
    "        filtered_df = df[df['ML_BFD'] == 1]\n",
    "\n",
    "        # Extract gage_id from the filename (assuming filename is the gage_id)\n",
    "        gage_id = os.path.splitext(filename)[0]\n",
    "\n",
    "        # Add a new column for gage_id\n",
    "        filtered_df['gage_id'] = gage_id\n",
    "\n",
    "        # Select and rename the necessary columns\n",
    "        filtered_df = filtered_df[['gage_id', 'date','Q', 'ML_BFD']]\n",
    "        filtered_df.columns = ['gage_id', 'date', 'q', 'bfd']\n",
    "\n",
    "        # Append to the compiled DataFrame\n",
    "        compiled_data = pd.concat([compiled_data, filtered_df], ignore_index=True)\n",
    "\n",
    "# Display the compiled DataFrame\n",
    "compiled_data\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  compiled_data = pd.concat([compiled_data, filtered_df], ignore_index=True)\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_91008/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         gage_id        date     q  bfd\n",
       "0       10015900  1958-04-01   0.0  1.0\n",
       "1       10015900  1958-04-02   0.0  1.0\n",
       "2       10015900  1958-04-03   0.0  1.0\n",
       "3       10015900  1958-04-04   0.0  1.0\n",
       "4       10015900  1958-04-05   0.0  1.0\n",
       "...          ...         ...   ...  ...\n",
       "900051  10058600  1986-09-10  35.0  1.0\n",
       "900052  10058600  1986-09-14  33.6  1.0\n",
       "900053  10058600  1986-09-24  32.9  1.0\n",
       "900054  10058600  1986-09-25  34.4  1.0\n",
       "900055  10058600  1986-09-28  32.1  1.0\n",
       "\n",
       "[900056 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gage_id</th>\n",
       "      <th>date</th>\n",
       "      <th>q</th>\n",
       "      <th>bfd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900051</th>\n",
       "      <td>10058600</td>\n",
       "      <td>1986-09-10</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900052</th>\n",
       "      <td>10058600</td>\n",
       "      <td>1986-09-14</td>\n",
       "      <td>33.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900053</th>\n",
       "      <td>10058600</td>\n",
       "      <td>1986-09-24</td>\n",
       "      <td>32.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900054</th>\n",
       "      <td>10058600</td>\n",
       "      <td>1986-09-25</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900055</th>\n",
       "      <td>10058600</td>\n",
       "      <td>1986-09-28</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900056 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## streamflow outliers",
   "id": "2c396af5f567d2d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:28:52.840825Z",
     "start_time": "2025-08-20T05:28:52.629493Z"
    }
   },
   "cell_type": "code",
   "source": "# Streamflow data preparation - no outlier detection needed\n# Flow variations are natural and should not be treated as outliers\n\nprint(\"Processing streamflow data...\")\nprint(f\"Total streamflow records: {len(compiled_data):,}\")\nprint(f\"Number of unique gages: {compiled_data['gage_id'].nunique()}\")\n\n# Simply use the compiled data as clean data since flow variations are natural\nclean_data = compiled_data.copy()\n\n# Display basic statistics by gage\ngage_stats = compiled_data.groupby('gage_id').agg({\n    'q': ['count', 'min', 'max', 'mean', 'std'],\n    'date': ['min', 'max']\n}).round(2)\n\ngage_stats.columns = ['record_count', 'min_flow', 'max_flow', 'mean_flow', 'std_flow', 'start_date', 'end_date']\n\nprint(f\"\\nStreamflow statistics by gage:\")\nprint(gage_stats)\n\nprint(f\"\\nStreamflow data ready for use - no outlier removal applied\")\nprint(f\"Final record count: {len(clean_data):,}\")",
   "id": "912170b77805c551",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing streamflow data...\n",
      "Total streamflow records: 900,056\n",
      "Number of unique gages: 70\n",
      "\n",
      "Streamflow statistics by gage:\n",
      "          record_count  min_flow  max_flow  mean_flow  std_flow  start_date  \\\n",
      "gage_id                                                                       \n",
      "10011500         21729     13.00     236.0      55.71     26.26  1942-07-28   \n",
      "10015700         11305      0.00      37.0       4.74      5.23  1957-10-01   \n",
      "10015900          6805      0.00      49.0       1.84      4.07  1958-04-01   \n",
      "10016900          6868      3.20     177.0      48.85     24.38  1984-08-11   \n",
      "10020100         12810      0.00     200.0      36.85     27.73  1961-10-01   \n",
      "...                ...       ...       ...        ...       ...         ...   \n",
      "10168500         15408      4.50      98.0      29.15     10.63  1930-10-01   \n",
      "10171000         23782      0.00     292.0     132.99     39.94  1942-12-01   \n",
      "10172700         20071      0.51       5.2       2.42      0.93  1958-06-26   \n",
      "10172860          3193     11.10      22.7      15.98      2.50  2005-10-01   \n",
      "10172952         14017      0.14       5.9       1.74      1.02  1971-08-05   \n",
      "\n",
      "            end_date  \n",
      "gage_id               \n",
      "10011500  2025-01-28  \n",
      "10015700  1997-09-30  \n",
      "10015900  1992-10-06  \n",
      "10016900  2025-01-28  \n",
      "10020100  2025-01-28  \n",
      "...              ...  \n",
      "10168500  1990-09-29  \n",
      "10171000  2025-01-20  \n",
      "10172700  2025-01-28  \n",
      "10172860  2019-10-02  \n",
      "10172952  2025-01-28  \n",
      "\n",
      "[70 rows x 7 columns]\n",
      "\n",
      "Streamflow data ready for use - no outlier removal applied\n",
      "Final record count: 900,056\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:28:53.476065Z",
     "start_time": "2025-08-20T05:28:53.378473Z"
    }
   },
   "cell_type": "code",
   "source": "# Display streamflow data summary - no outlier detection applied\nprint(\"Streamflow data summary:\")\nprint(f\"Total records: {len(clean_data):,}\")\nprint(f\"Date range: {clean_data['date'].min()} to {clean_data['date'].max()}\")\nprint(f\"Flow range: {clean_data['q'].min():.2f} to {clean_data['q'].max():.2f} cfs\")\nprint(f\"Number of gages: {clean_data['gage_id'].nunique()}\")\n\n# Show sample data\nprint(f\"\\nSample of streamflow data:\")\nprint(clean_data.head(10))",
   "id": "60ff42ab8de2de61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamflow data summary:\n",
      "Total records: 900,056\n",
      "Date range: 1902-10-01 to 2025-01-28\n",
      "Flow range: -0.00 to 1890.00 cfs\n",
      "Number of gages: 70\n",
      "\n",
      "Sample of streamflow data:\n",
      "    gage_id        date    q  bfd\n",
      "0  10015900  1958-04-01  0.0  1.0\n",
      "1  10015900  1958-04-02  0.0  1.0\n",
      "2  10015900  1958-04-03  0.0  1.0\n",
      "3  10015900  1958-04-04  0.0  1.0\n",
      "4  10015900  1958-04-05  0.0  1.0\n",
      "5  10015900  1958-04-06  0.0  1.0\n",
      "6  10015900  1958-04-07  0.0  1.0\n",
      "7  10015900  1958-04-08  0.0  1.0\n",
      "8  10015900  1958-04-09  0.0  1.0\n",
      "9  10015900  1958-04-10  0.0  1.0\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:28:54.005760Z",
     "start_time": "2025-08-20T05:28:53.976795Z"
    }
   },
   "cell_type": "code",
   "source": "clean_data=clean_data[['gage_id','date','q','bfd']]",
   "id": "89670ba06be535f2",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:28:54.713509Z",
     "start_time": "2025-08-20T05:28:54.697202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "compiled_data=clean_data.copy()\n",
    "compiled_data.head()"
   ],
   "id": "44a7c2f6ba937e4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    gage_id        date    q  bfd\n",
       "0  10015900  1958-04-01  0.0  1.0\n",
       "1  10015900  1958-04-02  0.0  1.0\n",
       "2  10015900  1958-04-03  0.0  1.0\n",
       "3  10015900  1958-04-04  0.0  1.0\n",
       "4  10015900  1958-04-05  0.0  1.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gage_id</th>\n",
       "      <th>date</th>\n",
       "      <th>q</th>\n",
       "      <th>bfd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:28:56.647656Z",
     "start_time": "2025-08-20T05:28:55.906188Z"
    }
   },
   "cell_type": "code",
   "source": "# Define the output directory\noutput_directory = '../data/processed/streamflow'\nos.makedirs(output_directory, exist_ok=True)\n\n# Define the output file path\noutput_file_path = os.path.join(output_directory, 'q_bfd_1.csv')\n\n# Save the streamflow DataFrame (no outlier removal applied)\nclean_data.to_csv(output_file_path, index=False)\n\nprint(f\"Saved streamflow data to: {output_file_path}\")\nprint(f\"Records saved: {len(clean_data):,}\")\nprint(\"Note: No outlier detection applied to streamflow data - flow variations are natural\")\n\n# Display the path where the file is saved\noutput_file_path",
   "id": "4e723dc4a496920e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved streamflow data to: ../data/processed/streamflow/q_bfd_1.csv\n",
      "Records saved: 900,056\n",
      "Note: No outlier detection applied to streamflow data - flow variations are natural\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/processed/streamflow/q_bfd_1.csv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PCHIP well wte",
   "id": "f9963235229c6ed9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:38:37.097814Z",
     "start_time": "2025-08-20T05:38:37.019605Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd\n\n# Load and examine the original groundwater time series data\nwell_ts = pd.read_csv('../data/raw/groundwater/GSLB_1900-2023_TS_with_aquifers.csv')\nwell_ts.columns = well_ts.columns.str.lower()\n\nprint(\"=== ORIGINAL GROUNDWATER DATA VALIDATION ===\")\nprint(f\"Data shape: {well_ts.shape}\")\nprint(f\"Columns: {well_ts.columns.tolist()}\")\n\n# Critical: Examine the original date format\nprint(f\"\\n=== DATE FORMAT ANALYSIS ===\")\nprint(\"Sample date values (original format):\")\nprint(well_ts['date'].head(20).tolist())\n\nprint(f\"\\nDate column data type: {well_ts['date'].dtype}\")\nprint(f\"Unique date count: {well_ts['date'].nunique():,}\")\n\n# Try to parse dates and check year distribution\nprint(f\"\\n=== DATETIME CONVERSION TEST ===\")\ntry:\n    test_dates = pd.to_datetime(well_ts['date'], errors='coerce')\n    valid_dates = test_dates.dropna()\n    \n    print(f\"Successfully parsed dates: {len(valid_dates):,} / {len(well_ts):,}\")\n    print(f\"Failed to parse: {test_dates.isna().sum():,}\")\n    \n    if len(valid_dates) > 0:\n        years = valid_dates.dt.year\n        print(f\"\\nYear range: {years.min()} to {years.max()}\")\n        print(f\"Year distribution (top 10):\")\n        year_counts = years.value_counts().sort_index().head(10)\n        for year, count in year_counts.items():\n            print(f\"  {year}: {count:,} records\")\n        \n        print(f\"\\nYear distribution (bottom 10):\")\n        year_counts_bottom = years.value_counts().sort_index().tail(10)\n        for year, count in year_counts_bottom.items():\n            print(f\"  {year}: {count:,} records\")\n        \n        # Check for potential year issues\n        problematic_years = years[(years < 1900) | (years > 2030)]\n        if len(problematic_years) > 0:\n            print(f\"\\n*** WARNING: Found {len(problematic_years)} records with problematic years ***\")\n            print(f\"Problematic year range: {problematic_years.min()} to {problematic_years.max()}\")\n        else:\n            print(f\"\\n✓ All years appear reasonable (1900-2030)\")\n            \nexcept Exception as e:\n    print(f\"Error parsing dates: {e}\")\n\n# Display basic data info\nprint(f\"\\n=== BASIC DATA INFO ===\")\nwell_ts.info()",
   "id": "e77a23592094b7d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:38:38.133786Z",
     "start_time": "2025-08-20T05:38:38.114591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def analyze_well_time_spans(well_ts):\n",
    "    \"\"\"\n",
    "    Analyze well time spans and calculate key statistics\n",
    "    Args:\n",
    "        well_ts: Dictionary with well data containing start_date, end_date and data_points\n",
    "    Returns:\n",
    "        DataFrame with time span statistics\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for well_id, well_data in well_ts.items():\n",
    "        start_date = pd.to_datetime(well_data['start_date'])\n",
    "        end_date = pd.to_datetime(well_data['end_date'])\n",
    "        time_span = (end_date - start_date).days / 365.0\n",
    "        density = well_data['data_points'] / time_span if time_span > 0 else 0\n",
    "        data.append({\n",
    "            \"well_id\": well_id,\n",
    "            \"time_span_years\": time_span,\n",
    "            \"data_density\": density,\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def generate_time_span_report(df):\n",
    "    \"\"\"\n",
    "    Generate summary report from well statistics DataFrame\n",
    "    Args:\n",
    "        df: DataFrame with well statistics\n",
    "    \"\"\"\n",
    "    print(f\"\\nSummary Statistics:\")\n",
    "    print(f\"- Total wells: {len(df):,}\")\n",
    "    if 'time_span_years' in df:\n",
    "        print(f\"- Time span range: {df['time_span_years'].min():.1f} - {df['time_span_years'].max():.1f} years\")\n",
    "        print(f\"- Average time span: {df['time_span_years'].mean():.1f} years\")\n",
    "    if 'data_density' in df:\n",
    "        print(f\"- Data density range: {df['data_density'].min():.1f} - {df['data_density'].max():.1f} points/year\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "well_ts = {\n",
    "    \"well_1\": {\"start_date\": \"2015-01-01\", \"end_date\": \"2020-01-01\", \"data_points\": 50},\n",
    "    \"well_2\": {\"start_date\": \"2010-06-15\", \"end_date\": \"2022-06-15\", \"data_points\": 100}\n",
    "}\n",
    "\n",
    "stats_df = analyze_well_time_spans(well_ts)\n",
    "generate_time_span_report(stats_df)\n"
   ],
   "id": "ad6b95758b0042e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics:\n",
      "- Total wells: 2\n",
      "- Time span range: 5.0 - 12.0 years\n",
      "- Average time span: 8.5 years\n",
      "- Data density range: 8.3 - 10.0 points/year\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## detect outliers",
   "id": "2f0227cdc4b6e82e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:38:40.772564Z",
     "start_time": "2025-08-20T05:38:40.757418Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n\nclass SimpleGroundwaterOutlierDetector:\n    \"\"\"Simplified groundwater data outlier detection class - for interpolation preparation\"\"\"\n    DATE_COLUMN = 'date'\n    WELL_ID_COLUMN = 'well_id'\n\n    def __init__(self, data):\n        self.data = data.copy()\n        self._validate_columns()\n        # Convert date column during initialization\n        self.data[self.DATE_COLUMN] = pd.to_datetime(self.data[self.DATE_COLUMN], errors='coerce')\n        # Remove rows with invalid dates\n        self.data = self.data.dropna(subset=[self.DATE_COLUMN])\n        self.results = None\n\n    def _validate_columns(self):\n        \"\"\"Validate that required columns exist in the data\"\"\"\n        required_columns = [self.DATE_COLUMN, self.WELL_ID_COLUMN, 'wte']\n        missing_columns = [col for col in required_columns if col not in self.data.columns]\n        if missing_columns:\n            raise ValueError(f\"Missing required columns: {missing_columns}\")\n\n    def detect_outliers(self, min_points=5, zscore_threshold=3.0, iqr_multiplier=2):\n        \"\"\"\n        Detect outliers using statistical methods only\n        \n        Args:\n            min_points: Minimum points needed for statistical tests \n            zscore_threshold: Z-score threshold for outlier detection\n            iqr_multiplier: IQR multiplier for outlier detection\n        \"\"\"\n        # Sort by well_id and date\n        self.data = self.data.sort_values([self.WELL_ID_COLUMN, self.DATE_COLUMN]).reset_index(drop=True)\n        results = []\n        well_stats = []\n\n        print(f\"Processing {self.data[self.WELL_ID_COLUMN].nunique()} wells for outlier detection...\")\n\n        for well_id in self.data[self.WELL_ID_COLUMN].unique():\n            well_data = self.data[self.data[self.WELL_ID_COLUMN] == well_id].copy()\n            n_points = len(well_data)\n\n            # Initialize outlier flags\n            well_data['is_outlier_zscore'] = False\n            well_data['is_outlier_iqr'] = False\n            well_data['is_outlier'] = False\n\n            if n_points >= min_points:\n                wte_values = well_data['wte'].values\n\n                # 1. Statistical outlier detection (Z-score method)\n                try:\n                    z_scores = np.abs(stats.zscore(wte_values, nan_policy='omit'))\n                    is_zscore_outlier = z_scores > zscore_threshold\n                    well_data['is_outlier_zscore'] = is_zscore_outlier\n                except:\n                    pass\n\n                # 2. Statistical outlier detection (IQR method)\n                try:\n                    Q1, Q3 = np.nanpercentile(wte_values, [25, 75])\n                    IQR = Q3 - Q1\n                    if IQR > 0:\n                        lower_bound = Q1 - iqr_multiplier * IQR\n                        upper_bound = Q3 + iqr_multiplier * IQR\n                        is_iqr_outlier = (wte_values < lower_bound) | (wte_values > upper_bound)\n                        well_data['is_outlier_iqr'] = is_iqr_outlier\n                except:\n                    pass\n\n                # Combine outlier detection methods (conservative approach)\n                # Flag as outlier only if detected by both methods\n                well_data['is_outlier'] = well_data['is_outlier_zscore'] & well_data['is_outlier_iqr']\n\n                # Collect statistics for this well\n                well_stats.append({\n                    'well_id': well_id,\n                    'total_points': n_points,\n                    'zscore_outliers': well_data['is_outlier_zscore'].sum(),\n                    'iqr_outliers': well_data['is_outlier_iqr'].sum(),\n                    'total_outliers': well_data['is_outlier'].sum(),\n                    'outlier_percentage': (well_data['is_outlier'].sum() / n_points * 100),\n                    'date_range_days': (well_data[self.DATE_COLUMN].max() - \n                                      well_data[self.DATE_COLUMN].min()).days,\n                    'wte_range': well_data['wte'].max() - well_data['wte'].min()\n                })\n\n            else:\n                # For wells with insufficient data, don't flag any outliers\n                well_data['is_outlier_zscore'] = False\n                well_data['is_outlier_iqr'] = False\n                well_data['is_outlier'] = False\n\n            results.append(well_data)\n\n        if results:\n            self.results = pd.concat(results, ignore_index=True)\n            \n            # Display summary statistics\n            stats_df = pd.DataFrame(well_stats)\n            if len(stats_df) > 0:\n                print(f\"\\nWell outlier detection summary:\")\n                print(f\"- Wells processed: {len(stats_df)}\")\n                print(f\"- Total outliers detected: {self.results['is_outlier'].sum():,}\")\n                print(f\"- By Z-score method: {self.results['is_outlier_zscore'].sum():,}\")\n                print(f\"- By IQR method: {self.results['is_outlier_iqr'].sum():,}\")\n                \n                print(f\"\\nOutlier percentage statistics:\")\n                print(f\"- Mean outlier percentage per well: {stats_df['outlier_percentage'].mean():.2f}%\")\n                print(f\"- Max outlier percentage per well: {stats_df['outlier_percentage'].max():.2f}%\")\n                print(f\"- Wells with >10% outliers: {(stats_df['outlier_percentage'] > 10).sum()}\")\n\n        return self.results\n\n    def get_clean_data(self):\n        \"\"\"Get clean data suitable for interpolation\"\"\"\n        if self.results is None:\n            return None\n\n        clean_data = self.results[~self.results['is_outlier']].copy()\n\n        # Print interpolation readiness stats\n        well_stats = clean_data.groupby(self.WELL_ID_COLUMN).size()\n        print(f\"\\nInterpolation readiness summary:\")\n        print(f\"- Wells with no data after cleaning: {(well_stats == 0).sum()}\")\n        print(f\"- Wells with 1-2 points: {((well_stats >= 1) & (well_stats <= 2)).sum()}\")\n        print(f\"- Wells with 3+ points: {(well_stats >= 3).sum()} (suitable for PCHIP)\")\n\n        return clean_data\n\n\ndef clean_well_data_for_interpolation(well_ts, min_points=5):\n    \"\"\"Main function to clean groundwater data for interpolation\"\"\"\n    detector = SimpleGroundwaterOutlierDetector(well_ts)\n    detector.detect_outliers(min_points=min_points)\n    return detector.get_clean_data()",
   "id": "c135dc6921039aaa",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:07:31.434823Z",
     "start_time": "2025-08-13T05:07:31.432860Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5127e0d9e68ebec4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:38:51.544324Z",
     "start_time": "2025-08-20T05:38:47.469427Z"
    }
   },
   "cell_type": "code",
   "source": "# Reload the well_ts DataFrame since it was overwritten by the dictionary example\nwell_ts = pd.read_csv('../data/raw/groundwater/GSLB_1900-2023_TS_with_aquifers.csv')\nwell_ts.columns = well_ts.columns.str.lower()\n\n# Now use the actual well_ts DataFrame for outlier detection\nclean_data = clean_well_data_for_interpolation(well_ts)",
   "id": "328e97661ca3e7f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8602 wells for outlier detection...\n",
      "\n",
      "Well outlier detection summary:\n",
      "- Wells processed: 2338\n",
      "- Total outliers detected: 911\n",
      "- By Z-score method: 1,049\n",
      "- By IQR method: 3,247\n",
      "\n",
      "Outlier percentage statistics:\n",
      "- Mean outlier percentage per well: 0.57%\n",
      "- Max outlier percentage per well: 9.09%\n",
      "- Wells with >10% outliers: 0\n",
      "\n",
      "Interpolation readiness summary:\n",
      "- Wells with no data after cleaning: 0\n",
      "- Wells with 1-2 points: 5664\n",
      "- Wells with 3+ points: 2938 (suitable for PCHIP)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PCHIP wte",
   "id": "5fc0624e732e919b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:42:04.270234Z",
     "start_time": "2025-08-20T05:42:04.249914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "\n",
    "# Convert all column names to lowercase\n",
    "clean_data.columns = clean_data.columns.str.lower()\n",
    "\n",
    "# Convert date column to datetime format\n",
    "clean_data['date'] = pd.to_datetime(clean_data['date'])\n",
    "\n",
    "# Count data points for each well\n",
    "well_counts = clean_data['well_id'].value_counts()\n",
    "total_wells = len(well_counts)\n",
    "wells_with_one_point = (well_counts == 1).sum()\n",
    "wells_with_two_points = (well_counts == 2).sum()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Total number of wells: {total_wells}\")\n",
    "print(f\"Number of wells with only one data point: {wells_with_one_point}\")\n",
    "print(f\"Number of wells with only two data points: {wells_with_two_points}\")\n"
   ],
   "id": "c0433c14548a00bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wells: 8602\n",
      "Number of wells with only one data point: 4837\n",
      "Number of wells with only two data points: 827\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:42:05.207596Z",
     "start_time": "2025-08-20T05:42:05.200556Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd\nimport numpy as np\nfrom scipy.interpolate import PchipInterpolator\n\n\ndef interpolate_daily_pchip(well_ts):\n    \"\"\"\n    Perform daily PCHIP interpolation on groundwater well time series data\n    \n    Args:\n        well_ts: DataFrame containing well_id, date, and wte (water table elevation) columns\n        \n    Returns:\n        DataFrame with daily interpolated values for each well\n    \"\"\"\n    well_ts = well_ts.copy()\n    \n    # Critical: Proper datetime conversion and validation\n    print(\"Converting dates to datetime format...\")\n    well_ts['date'] = pd.to_datetime(well_ts['date'], errors='coerce')\n    \n    # Remove rows with invalid dates\n    invalid_dates = well_ts['date'].isna()\n    if invalid_dates.sum() > 0:\n        print(f\"Warning: {invalid_dates.sum()} rows with invalid dates removed\")\n        well_ts = well_ts.dropna(subset=['date'])\n    \n    # Validate date ranges to ensure reasonable years\n    min_year = well_ts['date'].dt.year.min()\n    max_year = well_ts['date'].dt.year.max()\n    print(f\"Date range: {min_year} to {max_year}\")\n    \n    # Flag potential year issues\n    if min_year < 1900 or max_year > 2030:\n        print(f\"WARNING: Potentially problematic date range detected!\")\n        print(f\"Please verify the year information is correct\")\n    \n    # Critical: Sort by well_id and date to ensure proper chronological order\n    well_ts = well_ts.sort_values(['well_id', 'date']).reset_index(drop=True)\n    print(f\"Processing {well_ts['well_id'].nunique()} wells for PCHIP interpolation...\")\n\n    interpolated_list = []\n    skipped_wells = 0\n\n    for well_id, group in well_ts.groupby('well_id'):\n        # Skip wells with less than 2 observations (minimum required for interpolation)\n        if len(group) < 2:\n            skipped_wells += 1\n            continue\n\n        # Ensure group is sorted by date (critical for proper interpolation)\n        group = group.sort_values('date').reset_index(drop=True)\n        \n        # Check for duplicate dates and handle them\n        if group['date'].duplicated().any():\n            print(f\"Warning: Well {well_id} has duplicate dates, averaging WTE values\")\n            group = group.groupby('date')['wte'].mean().reset_index()\n            group['well_id'] = well_id\n\n        # Get date range\n        start_date = group['date'].min()\n        end_date = group['date'].max()\n        \n        # Skip wells with very short time ranges (less than 1 day)\n        if (end_date - start_date).days < 1:\n            skipped_wells += 1\n            continue\n\n        # Generate daily date sequence \n        full_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n\n        # Convert dates to ordinal numbers for interpolation\n        # This preserves the exact datetime information\n        x_obs = group['date'].map(pd.Timestamp.toordinal)\n        y_obs = group['wte'].values\n\n        # Verify we have valid data for interpolation\n        if len(x_obs) != len(y_obs) or len(x_obs) < 2:\n            skipped_wells += 1\n            continue\n\n        # Perform PCHIP interpolation\n        try:\n            interpolator = PchipInterpolator(x_obs, y_obs)\n            x_new = full_dates.map(pd.Timestamp.toordinal)\n            y_new = interpolator(x_new)\n\n            # Create interpolated DataFrame \n            df_interp = pd.DataFrame({\n                'well_id': well_id,\n                'date': full_dates,\n                'wte': y_new\n            })\n\n            interpolated_list.append(df_interp)\n            \n        except Exception as e:\n            print(f\"Error interpolating well {well_id}: {e}\")\n            skipped_wells += 1\n            continue\n\n    print(f\"Successfully interpolated {len(interpolated_list)} wells\")\n    print(f\"Skipped {skipped_wells} wells due to insufficient data or errors\")\n\n    if interpolated_list:\n        interpolated_df = pd.concat(interpolated_list, ignore_index=True)\n        \n        # Final validation of interpolated data\n        print(f\"\\nInterpolation results:\")\n        print(f\"- Total interpolated records: {len(interpolated_df):,}\")\n        print(f\"- Date range: {interpolated_df['date'].min()} to {interpolated_df['date'].max()}\")\n        print(f\"- WTE range: {interpolated_df['wte'].min():.2f} to {interpolated_df['wte'].max():.2f}\")\n        \n        return interpolated_df\n    else:\n        print(\"No wells could be interpolated!\")\n        return pd.DataFrame()",
   "id": "1d6b663da6f1fbbd",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:42:06.480495Z",
     "start_time": "2025-08-20T05:42:06.470235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "well_info = pd.read_csv('../data/raw/groundwater/GSLB_1900-2023_wells_with_aquifers.csv')\n",
    "well_info.columns = well_info.columns.str.lower()\n"
   ],
   "id": "7b5aa149fac43e93",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:42:07.544041Z",
     "start_time": "2025-08-20T05:42:07.537988Z"
    }
   },
   "cell_type": "code",
   "source": "well_info.info()",
   "id": "d8bc4c2b39586526",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8752 entries, 0 to 8751\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   well_id       8752 non-null   int64  \n",
      " 1   well_name     8752 non-null   object \n",
      " 2   lat_dec       8752 non-null   float64\n",
      " 3   long_dec      8752 non-null   float64\n",
      " 4   gse           8752 non-null   float64\n",
      " 5   aquiferid     8752 non-null   int64  \n",
      " 6   aquifer_name  8752 non-null   object \n",
      " 7   state         8752 non-null   object \n",
      "dtypes: float64(3), int64(2), object(3)\n",
      "memory usage: 547.1+ KB\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:42:34.096660Z",
     "start_time": "2025-08-20T05:42:08.716590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "daily_interp_df = interpolate_daily_pchip(clean_data)\n",
    "# Merge well information with well_info data\n",
    "merged_data = pd.merge(daily_interp_df, well_info, on='well_id', how='left')\n",
    "\n",
    "# Rename columns\n",
    "merged_data.rename(columns={'lat_dec': 'well_lat', 'long_dec': 'well_lon'}, inplace=True)\n",
    "merged_data = merged_data[['well_id', 'date', 'wte', 'well_lat', 'well_lon', 'gse']]\n",
    "# Display merged data\n",
    "merged_data.head()\n"
   ],
   "id": "b743307617abb7d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting dates to datetime format...\n",
      "Date range: 1906 to 2023\n",
      "Processing 8602 wells for PCHIP interpolation...\n",
      "Successfully interpolated 3765 wells\n",
      "Skipped 4837 wells due to insufficient data or errors\n",
      "\n",
      "Interpolation results:\n",
      "- Total interpolated records: 26,260,962\n",
      "- Date range: 1915-08-01 00:00:00 to 2023-12-21 00:00:00\n",
      "- WTE range: 4072.00 to 7845.81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "           well_id       date          wte   well_lat    well_lon     gse\n",
       "0  382113113435401 2008-09-03  5395.950000  38.353571 -113.732473  5775.0\n",
       "1  382113113435401 2008-09-04  5395.950539  38.353571 -113.732473  5775.0\n",
       "2  382113113435401 2008-09-05  5395.951113  38.353571 -113.732473  5775.0\n",
       "3  382113113435401 2008-09-06  5395.951721  38.353571 -113.732473  5775.0\n",
       "4  382113113435401 2008-09-07  5395.952363  38.353571 -113.732473  5775.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well_id</th>\n",
       "      <th>date</th>\n",
       "      <th>wte</th>\n",
       "      <th>well_lat</th>\n",
       "      <th>well_lon</th>\n",
       "      <th>gse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>382113113435401</td>\n",
       "      <td>2008-09-03</td>\n",
       "      <td>5395.950000</td>\n",
       "      <td>38.353571</td>\n",
       "      <td>-113.732473</td>\n",
       "      <td>5775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>382113113435401</td>\n",
       "      <td>2008-09-04</td>\n",
       "      <td>5395.950539</td>\n",
       "      <td>38.353571</td>\n",
       "      <td>-113.732473</td>\n",
       "      <td>5775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>382113113435401</td>\n",
       "      <td>2008-09-05</td>\n",
       "      <td>5395.951113</td>\n",
       "      <td>38.353571</td>\n",
       "      <td>-113.732473</td>\n",
       "      <td>5775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>382113113435401</td>\n",
       "      <td>2008-09-06</td>\n",
       "      <td>5395.951721</td>\n",
       "      <td>38.353571</td>\n",
       "      <td>-113.732473</td>\n",
       "      <td>5775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>382113113435401</td>\n",
       "      <td>2008-09-07</td>\n",
       "      <td>5395.952363</td>\n",
       "      <td>38.353571</td>\n",
       "      <td>-113.732473</td>\n",
       "      <td>5775.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:43:48.680954Z",
     "start_time": "2025-08-20T05:42:48.017874Z"
    }
   },
   "cell_type": "code",
   "source": "merged_data.to_csv('../data/processed/well_pchip.csv', index=False)",
   "id": "1faa253ce3e3878b",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2e871a0f3cff237e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
