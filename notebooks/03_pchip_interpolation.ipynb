{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Streamflow ML results",
   "id": "3d2b54810f170636"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## filter q (bfd=1)",
   "id": "41a532437f802c78"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-13T04:48:49.732378Z",
     "start_time": "2025-08-13T04:48:48.792008Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# from main_jupyter import final_measurements_delta\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "directory = '../data/raw/streamflow/GSLB_ML'\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "compiled_data = pd.DataFrame(columns=['gage_id', 'date', 'q', 'bfd'])\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Filter rows where ML_BFD is 1\n",
    "        filtered_df = df[df['ML_BFD'] == 1]\n",
    "\n",
    "        # Extract gage_id from the filename (assuming filename is the gage_id)\n",
    "        gage_id = os.path.splitext(filename)[0]\n",
    "\n",
    "        # Add a new column for gage_id\n",
    "        filtered_df['gage_id'] = gage_id\n",
    "\n",
    "        # Select and rename the necessary columns\n",
    "        filtered_df = filtered_df[['gage_id', 'date','Q', 'ML_BFD']]\n",
    "        filtered_df.columns = ['gage_id', 'date', 'q', 'bfd']\n",
    "\n",
    "        # Append to the compiled DataFrame\n",
    "        compiled_data = pd.concat([compiled_data, filtered_df], ignore_index=True)\n",
    "\n",
    "# Display the compiled DataFrame\n",
    "compiled_data\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  compiled_data = pd.concat([compiled_data, filtered_df], ignore_index=True)\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n",
      "/var/folders/fk/mzjttwrn7rn5nvcfhpgm4mrc0000gq/T/ipykernel_12160/2827158917.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['gage_id'] = gage_id\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         gage_id        date     q  bfd\n",
       "0       10015900  1958-04-01   0.0  1.0\n",
       "1       10015900  1958-04-02   0.0  1.0\n",
       "2       10015900  1958-04-03   0.0  1.0\n",
       "3       10015900  1958-04-04   0.0  1.0\n",
       "4       10015900  1958-04-05   0.0  1.0\n",
       "...          ...         ...   ...  ...\n",
       "900051  10058600  1986-09-10  35.0  1.0\n",
       "900052  10058600  1986-09-14  33.6  1.0\n",
       "900053  10058600  1986-09-24  32.9  1.0\n",
       "900054  10058600  1986-09-25  34.4  1.0\n",
       "900055  10058600  1986-09-28  32.1  1.0\n",
       "\n",
       "[900056 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gage_id</th>\n",
       "      <th>date</th>\n",
       "      <th>q</th>\n",
       "      <th>bfd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900051</th>\n",
       "      <td>10058600</td>\n",
       "      <td>1986-09-10</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900052</th>\n",
       "      <td>10058600</td>\n",
       "      <td>1986-09-14</td>\n",
       "      <td>33.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900053</th>\n",
       "      <td>10058600</td>\n",
       "      <td>1986-09-24</td>\n",
       "      <td>32.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900054</th>\n",
       "      <td>10058600</td>\n",
       "      <td>1986-09-25</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900055</th>\n",
       "      <td>10058600</td>\n",
       "      <td>1986-09-28</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900056 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## streamflow outliers",
   "id": "2c396af5f567d2d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T04:52:06.124951Z",
     "start_time": "2025-08-13T04:52:05.984171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "class SimpleOutlierDetector:\n",
    "    \"\"\"Simplified outlier detection class\"\"\"\n",
    "\n",
    "    def __init__(self, data, column):\n",
    "        self.data = data.copy()\n",
    "        self.column = column\n",
    "        self.results = None\n",
    "\n",
    "    def detect_outliers(self, zscore_threshold=3.0, iqr_multiplier=1.5):\n",
    "        \"\"\"Detect outliers\"\"\"\n",
    "        data = self.data.copy()\n",
    "        # Initialize outlier flag columns\n",
    "        data['is_outlier_zscore'] = False\n",
    "        data['is_outlier_iqr'] = False\n",
    "\n",
    "        # 1. Z-score method\n",
    "        try:\n",
    "            z_scores = np.abs(stats.zscore(data[self.column], nan_policy='omit'))\n",
    "            data['is_outlier_zscore'] = z_scores > zscore_threshold\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # 2. IQR method\n",
    "        try:\n",
    "            Q1 = np.nanpercentile(data[self.column], 25)\n",
    "            Q3 = np.nanpercentile(data[self.column], 75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - iqr_multiplier * IQR\n",
    "            upper_bound = Q3 + iqr_multiplier * IQR\n",
    "            data['is_outlier_iqr'] = (data[self.column] < lower_bound) | (data[self.column] > upper_bound)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Combined outlier detection\n",
    "        data['is_outlier_any'] = data[['is_outlier_zscore', 'is_outlier_iqr']].any(axis=1)\n",
    "\n",
    "        self.results = data\n",
    "        return self.results\n",
    "\n",
    "    def get_clean_data(self):\n",
    "        \"\"\"Get clean data\"\"\"\n",
    "        if self.results is None:\n",
    "            raise ValueError(\"Please run detect_outliers() method first\")\n",
    "        return self.results[~self.results['is_outlier_any']].copy()\n",
    "\n",
    "\n",
    "# Usage example\n",
    "detector = SimpleOutlierDetector(compiled_data, 'q')\n",
    "outlier_results = detector.detect_outliers()\n",
    "clean_data = detector.get_clean_data()\n",
    "\n",
    "# Display clean data\n",
    "print(clean_data.head())\n",
    "\n",
    "\n"
   ],
   "id": "912170b77805c551",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gage_id        date    q  bfd  is_outlier_zscore  is_outlier_iqr  \\\n",
      "0  10015900  1958-04-01  0.0  1.0              False           False   \n",
      "1  10015900  1958-04-02  0.0  1.0              False           False   \n",
      "2  10015900  1958-04-03  0.0  1.0              False           False   \n",
      "3  10015900  1958-04-04  0.0  1.0              False           False   \n",
      "4  10015900  1958-04-05  0.0  1.0              False           False   \n",
      "\n",
      "   is_outlier_any  \n",
      "0           False  \n",
      "1           False  \n",
      "2           False  \n",
      "3           False  \n",
      "4           False  \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T04:52:44.053866Z",
     "start_time": "2025-08-13T04:52:43.962352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get detection results\n",
    "outlier_results = detector.detect_outliers()\n",
    "\n",
    "# Display total number of outliers detected\n",
    "total_outliers = outlier_results['is_outlier_any'].sum()\n",
    "print(f\"Total number of outliers detected: {total_outliers}\")\n",
    "\n",
    "# Display number of outliers detected by each method\n",
    "zscore_outliers = outlier_results['is_outlier_zscore'].sum()\n",
    "iqr_outliers = outlier_results['is_outlier_iqr'].sum()\n",
    "\n",
    "print(f\"Number of outliers detected by Z-score method: {zscore_outliers}\")\n",
    "print(f\"Number of outliers detected by IQR method: {iqr_outliers}\")\n",
    "\n",
    "# Mark records detected as outliers by both methods\n",
    "outlier_results['is_outlier_both'] = outlier_results['is_outlier_zscore'] & outlier_results['is_outlier_iqr']\n",
    "\n",
    "# Remove records that are outliers by both methods\n",
    "clean_data = outlier_results[~outlier_results['is_outlier_both']].copy()\n",
    "\n",
    "# Display summary of data cleaning\n",
    "removed_count = outlier_results['is_outlier_both'].sum()\n",
    "print(f\"Number of outliers removed (detected by both methods): {removed_count}\")\n",
    "print(f\"Number of records after cleaning: {len(clean_data)}\")\n"
   ],
   "id": "60ff42ab8de2de61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outliers detected: 35377\n",
      "Number of outliers detected by Z-score method: 14340\n",
      "Number of outliers detected by IQR method: 35377\n",
      "Number of outliers removed (detected by both methods): 14340\n",
      "Number of records after cleaning: 885716\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T04:53:15.780772Z",
     "start_time": "2025-08-13T04:53:15.755125Z"
    }
   },
   "cell_type": "code",
   "source": "clean_data=clean_data[['gage_id','date','q','bfd']]",
   "id": "89670ba06be535f2",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T04:54:15.255996Z",
     "start_time": "2025-08-13T04:54:15.221943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "compiled_data=clean_data.copy()\n",
    "compiled_data.head()"
   ],
   "id": "44a7c2f6ba937e4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    gage_id        date    q  bfd\n",
       "0  10015900  1958-04-01  0.0  1.0\n",
       "1  10015900  1958-04-02  0.0  1.0\n",
       "2  10015900  1958-04-03  0.0  1.0\n",
       "3  10015900  1958-04-04  0.0  1.0\n",
       "4  10015900  1958-04-05  0.0  1.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gage_id</th>\n",
       "      <th>date</th>\n",
       "      <th>q</th>\n",
       "      <th>bfd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10015900</td>\n",
       "      <td>1958-04-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T04:57:25.741140Z",
     "start_time": "2025-08-13T04:57:24.696485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the output directory\n",
    "output_directory = '../data/processed/streamflow'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = os.path.join(output_directory, 'q_bfd_1.csv')\n",
    "\n",
    "# Save the compiled DataFrame to a CSV file\n",
    "compiled_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the path where the file is saved\n",
    "output_file_path\n"
   ],
   "id": "4e723dc4a496920e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/processed/streamflow/q_bfd_1.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PCHIP well wte",
   "id": "f9963235229c6ed9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:01:00.159622Z",
     "start_time": "2025-08-13T05:01:00.076191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "well_ts = pd.read_csv('../data/raw/groundwater/GSLB_1900-2023_TS_with_aquifers.csv')\n",
    "well_ts.columns = well_ts.columns.str.lower()\n",
    "well_ts.info()\n"
   ],
   "id": "e77a23592094b7d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 177209 entries, 0 to 177208\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   aquiferid  177209 non-null  int64  \n",
      " 1   well_id    177209 non-null  int64  \n",
      " 2   date       177209 non-null  object \n",
      " 3   wte        177209 non-null  float64\n",
      " 4   state      177209 non-null  object \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:02:09.846743Z",
     "start_time": "2025-08-13T05:02:09.812537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def analyze_well_time_spans(well_ts):\n",
    "    \"\"\"\n",
    "    Analyze well time spans and calculate key statistics\n",
    "    Args:\n",
    "        well_ts: Dictionary with well data containing start_date, end_date and data_points\n",
    "    Returns:\n",
    "        DataFrame with time span statistics\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for well_id, well_data in well_ts.items():\n",
    "        start_date = pd.to_datetime(well_data['start_date'])\n",
    "        end_date = pd.to_datetime(well_data['end_date'])\n",
    "        time_span = (end_date - start_date).days / 365.0\n",
    "        density = well_data['data_points'] / time_span if time_span > 0 else 0\n",
    "        data.append({\n",
    "            \"well_id\": well_id,\n",
    "            \"time_span_years\": time_span,\n",
    "            \"data_density\": density,\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def generate_time_span_report(df):\n",
    "    \"\"\"\n",
    "    Generate summary report from well statistics DataFrame\n",
    "    Args:\n",
    "        df: DataFrame with well statistics\n",
    "    \"\"\"\n",
    "    print(f\"\\nSummary Statistics:\")\n",
    "    print(f\"- Total wells: {len(df):,}\")\n",
    "    if 'time_span_years' in df:\n",
    "        print(f\"- Time span range: {df['time_span_years'].min():.1f} - {df['time_span_years'].max():.1f} years\")\n",
    "        print(f\"- Average time span: {df['time_span_years'].mean():.1f} years\")\n",
    "    if 'data_density' in df:\n",
    "        print(f\"- Data density range: {df['data_density'].min():.1f} - {df['data_density'].max():.1f} points/year\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "well_ts = {\n",
    "    \"well_1\": {\"start_date\": \"2015-01-01\", \"end_date\": \"2020-01-01\", \"data_points\": 50},\n",
    "    \"well_2\": {\"start_date\": \"2010-06-15\", \"end_date\": \"2022-06-15\", \"data_points\": 100}\n",
    "}\n",
    "\n",
    "stats_df = analyze_well_time_spans(well_ts)\n",
    "generate_time_span_report(stats_df)\n"
   ],
   "id": "ad6b95758b0042e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics:\n",
      "- Total wells: 2\n",
      "- Time span range: 5.0 - 12.0 years\n",
      "- Average time span: 8.5 years\n",
      "- Data density range: 8.3 - 10.0 points/year\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## detect outliers",
   "id": "2f0227cdc4b6e82e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:20:50.190701Z",
     "start_time": "2025-08-13T05:20:50.176356Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n\nclass SimpleGroundwaterOutlierDetector:\n    \"\"\"Simplified groundwater data outlier detection class - for interpolation preparation\"\"\"\n    DATE_COLUMN = 'date'\n    WELL_ID_COLUMN = 'well_id'\n\n    def __init__(self, data):\n        self.data = data.copy()\n        self._validate_columns()\n        # Convert date column during initialization\n        self.data[self.DATE_COLUMN] = pd.to_datetime(self.data[self.DATE_COLUMN], errors='coerce')\n        self.results = None\n\n    def _validate_columns(self):\n        \"\"\"Validate that required columns exist in the data\"\"\"\n        required_columns = [self.DATE_COLUMN, self.WELL_ID_COLUMN]\n        missing_columns = [col for col in required_columns if col not in self.data.columns]\n        if missing_columns:\n            raise ValueError(f\"Missing required columns: {missing_columns}\")\n\n    def detect_outliers(self, min_points=5, zscore_threshold=3.0, iqr_multiplier=2):\n        \"\"\"\n        Detect outliers using statistical methods\n        \n        Args:\n            min_points: Minimum points needed for statistical tests \n            zscore_threshold: Z-score threshold for outlier detection\n            iqr_multiplier: IQR multiplier for outlier detection\n        \"\"\"\n        # Sort by well_id and date\n        self.data = self.data.sort_values([self.WELL_ID_COLUMN, self.DATE_COLUMN]).reset_index(drop=True)\n        results = []\n\n        for well_id in self.data['well_id'].unique():\n            well_data = self.data[self.data['well_id'] == well_id].copy()\n            n_points = len(well_data)\n\n            well_data['is_outlier'] = False\n\n            if n_points >= min_points:\n                wte_values = well_data['wte'].values\n\n                # Z-score method\n                z_scores = np.abs(stats.zscore(wte_values, nan_policy='omit'))\n                is_zscore_outlier = z_scores > zscore_threshold\n\n                # IQR method\n                Q1, Q3 = np.nanpercentile(wte_values, [25, 75])\n                IQR = Q3 - Q1\n                if IQR > 0:\n                    lower_bound = Q1 - iqr_multiplier * IQR\n                    upper_bound = Q3 + iqr_multiplier * IQR\n                    is_iqr_outlier = (wte_values < lower_bound) | (wte_values > upper_bound)\n\n                    # Combine methods\n                    well_data['is_outlier'] = is_zscore_outlier | is_iqr_outlier\n                results.append(well_data)\n\n        if results:\n            self.results = pd.concat(results, ignore_index=True)\n        return self.results\n\n    def get_clean_data(self):\n        \"\"\"Get clean data suitable for interpolation\"\"\"\n        if self.results is None:\n            return None\n\n        clean_data = self.results[~self.results['is_outlier']].copy()\n\n        # Print interpolation readiness stats\n        well_stats = clean_data.groupby('well_id').size()\n        print(f\"\\nInterpolation readiness summary:\")\n        print(f\"- Wells with no data: {(well_stats == 0).sum()}\")\n        print(f\"- Wells with 1-2 points: {((well_stats >= 1) & (well_stats <= 2)).sum()}\")\n        print(f\"- Wells with 3+ points: {(well_stats >= 3).sum()} (suitable for PCHIP)\")\n\n        return clean_data\n\n\ndef clean_well_data_for_interpolation(well_ts, min_points=5):\n    \"\"\"Main function to clean groundwater data for interpolation\"\"\"\n    detector = SimpleGroundwaterOutlierDetector(well_ts)\n    detector.detect_outliers(min_points=min_points)\n    return detector.get_clean_data()\n\n\ndef get_strictly_clean_data(detector):\n    \"\"\"\n    Extract strictly clean data by removing values detected as outliers by all methods\n    Returns clean_df and removed_df\n    \"\"\"\n    if detector.results is None:\n        raise ValueError(\"Please run detect_outliers() first\")\n\n    df = detector.results.copy()\n\n    # Ensure required columns exist\n    required_cols = ['is_outlier_zscore', 'is_outlier_iqr', 'is_outlier_modified_zscore']\n    if not all(col in df.columns for col in required_cols):\n        raise ValueError(\"Missing required outlier detection columns\")\n\n    # Strong outliers detected by all methods\n    df['is_strong_outlier'] = df['is_outlier_zscore'] & df['is_outlier_iqr'] & df['is_outlier_modified_zscore']\n\n    # Split into clean and removed data\n    clean_df = df[~df['is_strong_outlier']].copy()\n    removed_df = df[df['is_strong_outlier']].copy()\n\n    print(f\"Strong outliers removed:\")\n    print(f\"- Total records removed: {len(removed_df):,}\")\n    print(f\"- Clean records remaining: {len(clean_df):,}\")\n\n\n    return clean_df, removed_df",
   "id": "c135dc6921039aaa",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:07:31.434823Z",
     "start_time": "2025-08-13T05:07:31.432860Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5127e0d9e68ebec4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:20:56.693831Z",
     "start_time": "2025-08-13T05:20:54.432262Z"
    }
   },
   "cell_type": "code",
   "source": "# Reload the well_ts DataFrame since it was overwritten by the dictionary example\nwell_ts = pd.read_csv('../data/raw/groundwater/GSLB_1900-2023_TS_with_aquifers.csv')\nwell_ts.columns = well_ts.columns.str.lower()\n\n# Now use the actual well_ts DataFrame for outlier detection\nclean_data = clean_well_data_for_interpolation(well_ts)",
   "id": "328e97661ca3e7f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interpolation readiness summary:\n",
      "- Wells with no data: 0\n",
      "- Wells with 1-2 points: 0\n",
      "- Wells with 3+ points: 2338 (suitable for PCHIP)\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PCHIP wte",
   "id": "5fc0624e732e919b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:24:58.751966Z",
     "start_time": "2025-08-13T05:24:58.737424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "\n",
    "# Convert all column names to lowercase\n",
    "clean_data.columns = clean_data.columns.str.lower()\n",
    "\n",
    "# Convert date column to datetime format\n",
    "clean_data['date'] = pd.to_datetime(clean_data['date'])\n",
    "\n",
    "# Count data points for each well\n",
    "well_counts = clean_data['well_id'].value_counts()\n",
    "total_wells = len(well_counts)\n",
    "wells_with_one_point = (well_counts == 1).sum()\n",
    "wells_with_two_points = (well_counts == 2).sum()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Total number of wells: {total_wells}\")\n",
    "print(f\"Number of wells with only one data point: {wells_with_one_point}\")\n",
    "print(f\"Number of wells with only two data points: {wells_with_two_points}\")\n"
   ],
   "id": "c0433c14548a00bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of wells: 2338\n",
      "Number of wells with only one data point: 0\n",
      "Number of wells with only two data points: 0\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:27:03.601300Z",
     "start_time": "2025-08-13T05:27:03.595342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "\n",
    "\n",
    "def interpolate_daily_pchip(well_ts):\n",
    "    \"\"\"\n",
    "    Perform daily PCHIP interpolation on groundwater well time series data\n",
    "    \n",
    "    Args:\n",
    "        well_ts: DataFrame containing well_id, date, and wte (water table elevation) columns\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with daily interpolated values for each well\n",
    "    \"\"\"\n",
    "    well_ts = well_ts.copy()\n",
    "    well_ts['date'] = pd.to_datetime(well_ts['date'])\n",
    "    well_ts = well_ts.sort_values(['well_id', 'date'])\n",
    "\n",
    "    interpolated_list = []\n",
    "\n",
    "    for well_id, group in well_ts.groupby('well_id'):\n",
    "        # Skip wells with less than 2 observations (minimum required for interpolation)\n",
    "        if len(group) < 2:\n",
    "            continue\n",
    "\n",
    "        # Get date range\n",
    "        start_date = group['date'].min()\n",
    "        end_date = group['date'].max()\n",
    "\n",
    "        # Generate daily date sequence \n",
    "        full_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "        # Convert dates to ordinal numbers for interpolation\n",
    "        x_obs = group['date'].map(pd.Timestamp.toordinal)\n",
    "        y_obs = group['wte'].values\n",
    "\n",
    "        # Perform PCHIP interpolation\n",
    "        interpolator = PchipInterpolator(x_obs, y_obs)\n",
    "        x_new = full_dates.map(pd.Timestamp.toordinal)\n",
    "        y_new = interpolator(x_new)\n",
    "\n",
    "        # Create interpolated DataFrame \n",
    "        df_interp = pd.DataFrame({\n",
    "            'well_id': well_id,\n",
    "            'date': full_dates,\n",
    "            'wte': y_new\n",
    "        })\n",
    "\n",
    "        interpolated_list.append(df_interp)\n",
    "\n",
    "    interpolated_df = pd.concat(interpolated_list, ignore_index=True)\n",
    "    return interpolated_df\n"
   ],
   "id": "1d6b663da6f1fbbd",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:39:19.518332Z",
     "start_time": "2025-08-13T05:39:19.499245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "well_info = pd.read_csv('../data/raw/groundwater/GSLB_1900-2023_wells_with_aquifers.csv')\n",
    "well_info.columns = well_info.columns.str.lower()\n"
   ],
   "id": "7b5aa149fac43e93",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:39:21.582634Z",
     "start_time": "2025-08-13T05:39:21.576230Z"
    }
   },
   "cell_type": "code",
   "source": "well_info.info()",
   "id": "d8bc4c2b39586526",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8752 entries, 0 to 8751\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   well_id       8752 non-null   int64  \n",
      " 1   well_name     8752 non-null   object \n",
      " 2   lat_dec       8752 non-null   float64\n",
      " 3   long_dec      8752 non-null   float64\n",
      " 4   gse           8752 non-null   float64\n",
      " 5   aquiferid     8752 non-null   int64  \n",
      " 6   aquifer_name  8752 non-null   object \n",
      " 7   state         8752 non-null   object \n",
      "dtypes: float64(3), int64(2), object(3)\n",
      "memory usage: 547.1+ KB\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:39:43.912090Z",
     "start_time": "2025-08-13T05:39:24.484172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "daily_interp_df = interpolate_daily_pchip(clean_data)\n",
    "# Merge well information with well_info data\n",
    "merged_data = pd.merge(daily_interp_df, well_info, on='well_id', how='left')\n",
    "\n",
    "# Rename columns\n",
    "merged_data.rename(columns={'lat_dec': 'well_lat', 'long_dec': 'well_lon'}, inplace=True)\n",
    "merged_data = merged_data[['well_id', 'date', 'wte', 'well_lat', 'well_lon', 'gse']]\n",
    "# Display merged data\n",
    "merged_data.head()\n"
   ],
   "id": "b743307617abb7d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           well_id       date          wte   well_lat    well_lon     gse\n",
       "0  382113113435401 2008-09-03  5395.950000  38.353571 -113.732473  5775.0\n",
       "1  382113113435401 2008-09-04  5395.950539  38.353571 -113.732473  5775.0\n",
       "2  382113113435401 2008-09-05  5395.951113  38.353571 -113.732473  5775.0\n",
       "3  382113113435401 2008-09-06  5395.951721  38.353571 -113.732473  5775.0\n",
       "4  382113113435401 2008-09-07  5395.952363  38.353571 -113.732473  5775.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well_id</th>\n",
       "      <th>date</th>\n",
       "      <th>wte</th>\n",
       "      <th>well_lat</th>\n",
       "      <th>well_lon</th>\n",
       "      <th>gse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>382113113435401</td>\n",
       "      <td>2008-09-03</td>\n",
       "      <td>5395.950000</td>\n",
       "      <td>38.353571</td>\n",
       "      <td>-113.732473</td>\n",
       "      <td>5775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>382113113435401</td>\n",
       "      <td>2008-09-04</td>\n",
       "      <td>5395.950539</td>\n",
       "      <td>38.353571</td>\n",
       "      <td>-113.732473</td>\n",
       "      <td>5775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>382113113435401</td>\n",
       "      <td>2008-09-05</td>\n",
       "      <td>5395.951113</td>\n",
       "      <td>38.353571</td>\n",
       "      <td>-113.732473</td>\n",
       "      <td>5775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>382113113435401</td>\n",
       "      <td>2008-09-06</td>\n",
       "      <td>5395.951721</td>\n",
       "      <td>38.353571</td>\n",
       "      <td>-113.732473</td>\n",
       "      <td>5775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>382113113435401</td>\n",
       "      <td>2008-09-07</td>\n",
       "      <td>5395.952363</td>\n",
       "      <td>38.353571</td>\n",
       "      <td>-113.732473</td>\n",
       "      <td>5775.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T05:41:19.324209Z",
     "start_time": "2025-08-13T05:40:29.906544Z"
    }
   },
   "cell_type": "code",
   "source": "merged_data.to_csv('../data/processed/well_pchip.csv', index=False)",
   "id": "1faa253ce3e3878b",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2e871a0f3cff237e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
