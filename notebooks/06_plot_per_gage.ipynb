{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# load data",
   "id": "86415c3085319c34"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-13T17:24:20.363257Z",
     "start_time": "2025-08-13T17:24:20.361528Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:24:23.436955Z",
     "start_time": "2025-08-13T17:24:22.175935Z"
    }
   },
   "cell_type": "code",
   "source": "pip install openpyxl",
   "id": "3a23984f28401c80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.1.5)\r\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openpyxl) (2.0.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip3 install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:25:04.532769Z",
     "start_time": "2025-08-13T17:25:04.287484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gage_class=pd.read_excel('../data/raw/streamflow/GAGES-II_ref_non_ref.xlsx')\n",
    "gage_class.head()"
   ],
   "id": "c4952045c8f512e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     STAID    CLASS\n",
       "0  1011000  Non-ref\n",
       "1  1013500      Ref\n",
       "2  1015800  Non-ref\n",
       "3  1016500  Non-ref\n",
       "4  1017000  Non-ref"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STAID</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1011000</td>\n",
       "      <td>Non-ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013500</td>\n",
       "      <td>Ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015800</td>\n",
       "      <td>Non-ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016500</td>\n",
       "      <td>Non-ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017000</td>\n",
       "      <td>Non-ref</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:25:56.968178Z",
     "start_time": "2025-08-13T17:25:56.961980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gage_in_gslb=pd.read_csv('../data/raw/streamflow/gsl_nwm_gage.csv')\n",
    "gage_in_gslb.head()"
   ],
   "id": "3f867bc484b852c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         id                                               name  \\\n",
       "0  10011200  WEST FORK BEAR RIVER AT WHITNEY DAM - NR OAKLE...   \n",
       "1  10011500            BEAR RIVER NEAR UTAH-WYOMING STATE LINE   \n",
       "2  10015700  SULPHUR CR.AB.RES.BL.LA CHAPELLE CR.NR EVANSTO...   \n",
       "3  10015900       SULPHUR CREEK BL RES. - NEAR EVANSTON - WYO.   \n",
       "4  10016900                        BEAR RIVER AT EVANSTON - WY   \n",
       "\n",
       "                  River   latitude   longitude  elevation_m    state  \n",
       "0  WEST FORK BEAR RIVER  40.841614 -110.927119         2797     Utah  \n",
       "1            BEAR RIVER  40.965225 -110.853508         2432     Utah  \n",
       "2         SULPHUR CREEK  41.129114 -110.806563         2205  Wyoming  \n",
       "3         SULPHUR CREEK  41.156058 -110.835176         2173  Wyoming  \n",
       "4            BEAR RIVER  41.270224 -110.963793         2057  Wyoming  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>River</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation_m</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10011200</td>\n",
       "      <td>WEST FORK BEAR RIVER AT WHITNEY DAM - NR OAKLE...</td>\n",
       "      <td>WEST FORK BEAR RIVER</td>\n",
       "      <td>40.841614</td>\n",
       "      <td>-110.927119</td>\n",
       "      <td>2797</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10011500</td>\n",
       "      <td>BEAR RIVER NEAR UTAH-WYOMING STATE LINE</td>\n",
       "      <td>BEAR RIVER</td>\n",
       "      <td>40.965225</td>\n",
       "      <td>-110.853508</td>\n",
       "      <td>2432</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10015700</td>\n",
       "      <td>SULPHUR CR.AB.RES.BL.LA CHAPELLE CR.NR EVANSTO...</td>\n",
       "      <td>SULPHUR CREEK</td>\n",
       "      <td>41.129114</td>\n",
       "      <td>-110.806563</td>\n",
       "      <td>2205</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10015900</td>\n",
       "      <td>SULPHUR CREEK BL RES. - NEAR EVANSTON - WYO.</td>\n",
       "      <td>SULPHUR CREEK</td>\n",
       "      <td>41.156058</td>\n",
       "      <td>-110.835176</td>\n",
       "      <td>2173</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10016900</td>\n",
       "      <td>BEAR RIVER AT EVANSTON - WY</td>\n",
       "      <td>BEAR RIVER</td>\n",
       "      <td>41.270224</td>\n",
       "      <td>-110.963793</td>\n",
       "      <td>2057</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:26:27.516085Z",
     "start_time": "2025-08-13T17:26:27.382691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check the initial assignment\n",
    "print(\"Loading gage_class from Excel file...\")\n",
    "try:\n",
    "    gage_class = pd.read_excel('../data/raw/streamflow/GAGES-II_ref_non_ref.xlsx')\n",
    "    print(\"Successfully loaded gage_class as DataFrame\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading gage_class: {e}\")\n",
    "\n",
    "# Check the type and value of gage_class\n",
    "print(f\"Type of gage_class after loading: {type(gage_class)}\")\n",
    "print(gage_class.head())\n",
    "\n",
    "# Ensure gage_class is not overwritten\n",
    "# Add similar checks throughout your code where gage_class is used\n"
   ],
   "id": "8289e5d7139721e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gage_class from Excel file...\n",
      "Successfully loaded gage_class as DataFrame\n",
      "Type of gage_class after loading: <class 'pandas.core.frame.DataFrame'>\n",
      "     STAID    CLASS\n",
      "0  1011000  Non-ref\n",
      "1  1013500      Ref\n",
      "2  1015800  Non-ref\n",
      "3  1016500  Non-ref\n",
      "4  1017000  Non-ref\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:26:30.525324Z",
     "start_time": "2025-08-13T17:26:30.513402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensure the necessary columns are of string type for merging\n",
    "gage_class['STAID'] = gage_class['STAID'].astype(str)\n",
    "gage_in_gslb['id'] = gage_in_gslb['id'].astype(str)\n",
    "\n",
    "# Merge gage_in_gslb with gage_class to include the class information\n",
    "gage_in_gslb_with_class = gage_in_gslb.merge(\n",
    "    gage_class[['STAID', 'CLASS']],\n",
    "    left_on='id',\n",
    "    right_on='STAID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop the duplicate STAID column and rename CLASS to lowercase\n",
    "gage_in_gslb_with_class = gage_in_gslb_with_class.drop('STAID', axis=1)\n",
    "gage_in_gslb_with_class = gage_in_gslb_with_class.rename(columns={'CLASS': 'class'})\n",
    "\n",
    "# Calculate the total number of gages\n",
    "total_gages = len(gage_in_gslb_with_class)\n",
    "\n",
    "# Count the number of gages in each class\n",
    "class_counts = gage_in_gslb_with_class['class'].value_counts()\n",
    "\n",
    "# Calculate the percentage of gages in each class\n",
    "class_percentages = (class_counts / total_gages) * 100\n",
    "\n",
    "# Display the results\n",
    "print(\"Number of gages in each class:\")\n",
    "print(class_counts)\n",
    "print(\"\\nPercentage of gages in each class:\")\n",
    "print(class_percentages.round(2), \"%\")\n"
   ],
   "id": "40fba14d846ce2f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of gages in each class:\n",
      "class\n",
      "Non-ref    69\n",
      "Ref         9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage of gages in each class:\n",
      "class\n",
      "Non-ref    88.46\n",
      "Ref        11.54\n",
      "Name: count, dtype: float64 %\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:26:33.375774Z",
     "start_time": "2025-08-13T17:26:33.365493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the reference gages that are within the GSL basin\n",
    "ref_gages_in_gslb = gage_in_gslb_with_class[gage_in_gslb_with_class['class'] == 'Ref']\n",
    "\n",
    "# Display the reference gages in GSL basin with their details\n",
    "ref_gages_in_gslb[['id', 'name', 'River', 'latitude', 'longitude', 'state', 'class']]"
   ],
   "id": "cb7a7a371524f916",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          id                                              name  \\\n",
       "7   10023000                      BIG CREEK NEAR RANDOLPH - UT   \n",
       "13  10041000         THOMAS FORK NEAR WYOMING-IDAHO STATE LINE   \n",
       "16  10058600             BLOOMINGTON CREEK AT BLOOMINGTON - ID   \n",
       "20  10093000                       CUB RIVER NEAR PRESTON - ID   \n",
       "27  10109001  COM F LOGAN R AB ST D AND LO HP AND SM C N LO UT   \n",
       "51  10143500  CENTERVILLE CREEK ABV. DIV NEAR CENTERVILLE - UT   \n",
       "54  10148200                 TIE FORK NEAR SOLDIER SUMMIT - UT   \n",
       "75  10172700                     VERNON CREEK NEAR VERNON - UT   \n",
       "76  10172860                        WARM CREEK NEAR GANDY - UT   \n",
       "\n",
       "                   River   latitude   longitude    state class  \n",
       "7              BIG CREEK  41.609942 -111.254088     Utah   Ref  \n",
       "13           THOMAS FORK  42.402708 -111.025749  Wyoming   Ref  \n",
       "16     BLOOMINGTON CREEK  42.184650 -111.425763    Idaho   Ref  \n",
       "20             CUB RIVER  42.141037 -111.689388    Idaho   Ref  \n",
       "27  COM FORK LOGAN RIVER  41.744375 -111.784387     Utah   Ref  \n",
       "51     CENTERVILLE CREEK  40.916334 -111.862993     Utah   Ref  \n",
       "54              TIE FORK  39.949958 -111.216839     Utah   Ref  \n",
       "75          VERNON CREEK  39.979391 -112.380230     Utah   Ref  \n",
       "76            WARM CREEK  39.459528 -114.023722     Utah   Ref  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>River</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>state</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10023000</td>\n",
       "      <td>BIG CREEK NEAR RANDOLPH - UT</td>\n",
       "      <td>BIG CREEK</td>\n",
       "      <td>41.609942</td>\n",
       "      <td>-111.254088</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10041000</td>\n",
       "      <td>THOMAS FORK NEAR WYOMING-IDAHO STATE LINE</td>\n",
       "      <td>THOMAS FORK</td>\n",
       "      <td>42.402708</td>\n",
       "      <td>-111.025749</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10058600</td>\n",
       "      <td>BLOOMINGTON CREEK AT BLOOMINGTON - ID</td>\n",
       "      <td>BLOOMINGTON CREEK</td>\n",
       "      <td>42.184650</td>\n",
       "      <td>-111.425763</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>Ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10093000</td>\n",
       "      <td>CUB RIVER NEAR PRESTON - ID</td>\n",
       "      <td>CUB RIVER</td>\n",
       "      <td>42.141037</td>\n",
       "      <td>-111.689388</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>Ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10109001</td>\n",
       "      <td>COM F LOGAN R AB ST D AND LO HP AND SM C N LO UT</td>\n",
       "      <td>COM FORK LOGAN RIVER</td>\n",
       "      <td>41.744375</td>\n",
       "      <td>-111.784387</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>10143500</td>\n",
       "      <td>CENTERVILLE CREEK ABV. DIV NEAR CENTERVILLE - UT</td>\n",
       "      <td>CENTERVILLE CREEK</td>\n",
       "      <td>40.916334</td>\n",
       "      <td>-111.862993</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>10148200</td>\n",
       "      <td>TIE FORK NEAR SOLDIER SUMMIT - UT</td>\n",
       "      <td>TIE FORK</td>\n",
       "      <td>39.949958</td>\n",
       "      <td>-111.216839</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>10172700</td>\n",
       "      <td>VERNON CREEK NEAR VERNON - UT</td>\n",
       "      <td>VERNON CREEK</td>\n",
       "      <td>39.979391</td>\n",
       "      <td>-112.380230</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>10172860</td>\n",
       "      <td>WARM CREEK NEAR GANDY - UT</td>\n",
       "      <td>WARM CREEK</td>\n",
       "      <td>39.459528</td>\n",
       "      <td>-114.023722</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Ref</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9c6e6d40e62d205"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# plots",
   "id": "37592f18de8cfe31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:29:46.935335Z",
     "start_time": "2025-08-13T17:29:46.506289Z"
    }
   },
   "cell_type": "code",
   "source": "final_result_cleaned = pd.read_csv('../data/features/q_buffer2_pair_delta_30m.csv')",
   "id": "3cfeddcf325560e2",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:26:58.163564Z",
     "start_time": "2025-08-13T17:26:58.022947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert gage_id in both dataframes to string for merging\n",
    "final_result_cleaned['gage_id'] = final_result_cleaned['gage_id'].astype(str)\n",
    "gage_class['STAID'] = gage_class['STAID'].astype(str)\n",
    "\n",
    "# Merge final_result_cleaned with gage_class to add CLASS column\n",
    "final_result_cleaned = final_result_cleaned.merge(\n",
    "    gage_class[['STAID', 'CLASS']],\n",
    "    left_on='gage_id',\n",
    "    right_on='STAID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop redundant STAID column and rename CLASS to lowercase\n",
    "final_result_cleaned.drop('STAID', axis=1, inplace=True)\n",
    "final_result_cleaned.rename(columns={'CLASS': 'class'}, inplace=True)\n"
   ],
   "id": "7ed26bafa0f78502",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:27:00.354073Z",
     "start_time": "2025-08-13T17:27:00.331618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count the number of Non-ref and Ref gages\n",
    "gage_counts = final_result_cleaned['class'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Number of Non-ref gages:\", gage_counts.get('Non-ref', 0))\n",
    "print(\"Number of Ref gages:\", gage_counts.get('Ref', 0))\n"
   ],
   "id": "4af2df3689281bbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Non-ref gages: 429009\n",
      "Number of Ref gages: 0\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:27:02.391645Z",
     "start_time": "2025-08-13T17:27:02.378449Z"
    }
   },
   "cell_type": "code",
   "source": "final_result_cleaned.head()",
   "id": "9e59102db8483d93",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        well_id        date          wte     gse   gage_id   well_lat  \\\n",
       "0  3.946430e+14  1975-01-01  5954.322586  5955.0  10152000  39.778571   \n",
       "1  3.946430e+14  1975-01-02  5954.325175  5955.0  10152000  39.778571   \n",
       "2  3.946430e+14  1975-01-03  5954.327746  5955.0  10152000  39.778571   \n",
       "3  3.946430e+14  1975-01-04  5954.330300  5955.0  10152000  39.778571   \n",
       "4  3.946430e+14  1975-01-05  5954.332834  5955.0  10152000  39.778571   \n",
       "\n",
       "    well_lon   gage_lat    gage_lon   wte_meters     q  bfd    class  \n",
       "0 -111.48797  40.150232 -111.726039  1814.877524  96.0  1.0  Non-ref  \n",
       "1 -111.48797  40.150232 -111.726039  1814.878313  90.0  1.0  Non-ref  \n",
       "2 -111.48797  40.150232 -111.726039  1814.879097  90.0  1.0  Non-ref  \n",
       "3 -111.48797  40.150232 -111.726039  1814.879875  93.0  1.0  Non-ref  \n",
       "4 -111.48797  40.150232 -111.726039  1814.880648  95.0  1.0  Non-ref  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>well_id</th>\n",
       "      <th>date</th>\n",
       "      <th>wte</th>\n",
       "      <th>gse</th>\n",
       "      <th>gage_id</th>\n",
       "      <th>well_lat</th>\n",
       "      <th>well_lon</th>\n",
       "      <th>gage_lat</th>\n",
       "      <th>gage_lon</th>\n",
       "      <th>wte_meters</th>\n",
       "      <th>q</th>\n",
       "      <th>bfd</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.946430e+14</td>\n",
       "      <td>1975-01-01</td>\n",
       "      <td>5954.322586</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>10152000</td>\n",
       "      <td>39.778571</td>\n",
       "      <td>-111.48797</td>\n",
       "      <td>40.150232</td>\n",
       "      <td>-111.726039</td>\n",
       "      <td>1814.877524</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non-ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.946430e+14</td>\n",
       "      <td>1975-01-02</td>\n",
       "      <td>5954.325175</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>10152000</td>\n",
       "      <td>39.778571</td>\n",
       "      <td>-111.48797</td>\n",
       "      <td>40.150232</td>\n",
       "      <td>-111.726039</td>\n",
       "      <td>1814.878313</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non-ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.946430e+14</td>\n",
       "      <td>1975-01-03</td>\n",
       "      <td>5954.327746</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>10152000</td>\n",
       "      <td>39.778571</td>\n",
       "      <td>-111.48797</td>\n",
       "      <td>40.150232</td>\n",
       "      <td>-111.726039</td>\n",
       "      <td>1814.879097</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non-ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.946430e+14</td>\n",
       "      <td>1975-01-04</td>\n",
       "      <td>5954.330300</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>10152000</td>\n",
       "      <td>39.778571</td>\n",
       "      <td>-111.48797</td>\n",
       "      <td>40.150232</td>\n",
       "      <td>-111.726039</td>\n",
       "      <td>1814.879875</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non-ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.946430e+14</td>\n",
       "      <td>1975-01-05</td>\n",
       "      <td>5954.332834</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>10152000</td>\n",
       "      <td>39.778571</td>\n",
       "      <td>-111.48797</td>\n",
       "      <td>40.150232</td>\n",
       "      <td>-111.726039</td>\n",
       "      <td>1814.880648</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non-ref</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:27:04.013083Z",
     "start_time": "2025-08-13T17:27:03.962234Z"
    }
   },
   "cell_type": "code",
   "source": "final_result_cleaned.info()",
   "id": "6fc4d09f006e1ddd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 429009 entries, 0 to 429008\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   well_id     429009 non-null  float64\n",
      " 1   date        429009 non-null  object \n",
      " 2   wte         429009 non-null  float64\n",
      " 3   gse         429009 non-null  float64\n",
      " 4   gage_id     429009 non-null  object \n",
      " 5   well_lat    429009 non-null  float64\n",
      " 6   well_lon    429009 non-null  float64\n",
      " 7   gage_lat    429009 non-null  float64\n",
      " 8   gage_lon    429009 non-null  float64\n",
      " 9   wte_meters  429009 non-null  float64\n",
      " 10  q           429009 non-null  float64\n",
      " 11  bfd         429009 non-null  float64\n",
      " 12  class       429009 non-null  object \n",
      "dtypes: float64(10), object(3)\n",
      "memory usage: 42.6+ MB\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:43:18.372213Z",
     "start_time": "2025-08-13T17:43:11.599808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Re-merge with gage_class to ensure 'class' column exists\n",
    "final_result_cleaned['gage_id'] = final_result_cleaned['gage_id'].astype(str)\n",
    "gage_class['STAID'] = gage_class['STAID'].astype(str)\n",
    "\n",
    "# Merge to add CLASS column\n",
    "final_result_cleaned = final_result_cleaned.merge(\n",
    "    gage_class[['STAID', 'CLASS']],\n",
    "    left_on='gage_id',\n",
    "    right_on='STAID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Clean up and rename\n",
    "final_result_cleaned.drop('STAID', axis=1, inplace=True)\n",
    "final_result_cleaned.rename(columns={'CLASS': 'class'}, inplace=True)\n",
    "\n",
    "# Now run your plotting code\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Ensure the plots directory exists\n",
    "os.makedirs('../reports/figures/scatter_plots_delta_q_delta_wte', exist_ok=True)\n",
    "\n",
    "# Prepare a list to collect statistical data for CSV\n",
    "stats_data = []\n",
    "\n",
    "# Group by gage_id\n",
    "grouped = final_result_cleaned.groupby('gage_id')\n",
    "\n",
    "# Iterate over each group\n",
    "for gage_id, group in grouped:\n",
    "    group = group.dropna(subset=['delta_wte', 'delta_q'])\n",
    "    group['date'] = pd.to_datetime(group['date'])\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot: different wells as different colors\n",
    "    sns.scatterplot(\n",
    "        data=group,\n",
    "        x='delta_wte',\n",
    "        y='delta_q',\n",
    "        hue='well_id',\n",
    "        palette='viridis',\n",
    "        edgecolor='none',\n",
    "        legend=False  # suppress seaborn legend (we use our own)\n",
    "    )\n",
    "\n",
    "    legend_text = \"\"\n",
    "\n",
    "    if len(group) >= 2:\n",
    "        if len(group['delta_wte'].unique()) > 1:\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(\n",
    "                group['delta_wte'], group['delta_q']\n",
    "            )\n",
    "\n",
    "            delta_wte_range = pd.Series(group['delta_wte'].unique()).sort_values()\n",
    "            plt.plot(delta_wte_range, intercept + slope * delta_wte_range, 'r', linewidth=2)\n",
    "\n",
    "            # Get class value safely\n",
    "            try:\n",
    "                if 'class' in group.columns and len(group) > 0:\n",
    "                    class_values = group['class'].dropna()\n",
    "                    if len(class_values) > 0:\n",
    "                        class_value = class_values.iloc[0]\n",
    "                    else:\n",
    "                        class_value = 'Unknown'\n",
    "                else:\n",
    "                    class_value = 'Unknown'\n",
    "            except:\n",
    "                class_value = 'Unknown'\n",
    "\n",
    "            stats_data.append({\n",
    "                'gage_id': gage_id,\n",
    "                'num_wells': group['well_id'].nunique(),\n",
    "                'num_measurements': len(group),\n",
    "                'slope': slope,\n",
    "                'intercept': intercept,\n",
    "                'r_squared': r_value ** 2,\n",
    "                'p_value': p_value,\n",
    "                'class': class_value\n",
    "            })\n",
    "\n",
    "            legend_text = (\n",
    "                f\"Wells: {group['well_id'].nunique()}\\n\"\n",
    "                f\"Measurements: {len(group)}\\n\"\n",
    "                f\"Slope: {slope:.2f}\\n\"\n",
    "                f\"R²: {r_value ** 2:.2f}\\n\"\n",
    "                f\"p-value: {p_value:.4f}\"\n",
    "            )\n",
    "        else:\n",
    "            legend_text = (\n",
    "                f\"Wells: {group['well_id'].nunique()}\\n\"\n",
    "                f\"Measurements: {len(group)}\\n\"\n",
    "                \"All delta_wte values identical\\nNo regression line\"\n",
    "            )\n",
    "    else:\n",
    "        legend_text = (\n",
    "            f\"Wells: {group['well_id'].nunique()}\\n\"\n",
    "            f\"Measurements: {len(group)}\\n\"\n",
    "            \"Not enough data\"\n",
    "        )\n",
    "\n",
    "    # Map class names for display (with robust error handling)\n",
    "    try:\n",
    "        if 'class' in group.columns and len(group) > 0:\n",
    "            # Get non-null class values\n",
    "            class_values = group['class'].dropna()\n",
    "            if len(class_values) > 0:\n",
    "                class_display = str(class_values.iloc[0])\n",
    "                if class_display == 'Non-ref':\n",
    "                    class_display = 'Unregulated'\n",
    "                elif class_display == 'Ref':\n",
    "                    class_display = 'Regulated'\n",
    "                elif class_display in ['nan', 'None', '']:\n",
    "                    class_display = 'Unknown'\n",
    "            else:\n",
    "                class_display = 'Unknown'\n",
    "        else:\n",
    "            class_display = 'Unknown'\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing class for gage {gage_id}: {e}\")\n",
    "        class_display = 'Unknown'\n",
    "\n",
    "    # Title and labels\n",
    "    plt.title(f'Gage ID: {gage_id} - Class: {class_display}')\n",
    "    plt.xlabel('Delta WTE (ft)')\n",
    "    plt.ylabel('Delta Q')\n",
    "\n",
    "    # Grid and background\n",
    "    plt.gca().yaxis.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    plt.gca().xaxis.grid(False)\n",
    "    plt.gca().set_facecolor('white')\n",
    "\n",
    "    # Add transparent text box as a replacement for legend\n",
    "    plt.text(\n",
    "        0.98, 0.95,\n",
    "        legend_text,\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=10,\n",
    "        ha='right',\n",
    "        va='top',\n",
    "        linespacing=1.4,\n",
    "        bbox=dict(\n",
    "            facecolor='white',\n",
    "            edgecolor='black',\n",
    "            alpha=0.75,\n",
    "            boxstyle='square,pad=0.4'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'../reports/figures/scatter_plots_delta_q_delta_wte/gage_{gage_id}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Export statistics\n",
    "stats_df = pd.DataFrame(stats_data)\n",
    "stats_df.to_csv('../reports/figures/scatter_plots_delta_q_delta_wte/scatter_delta_q_delta_wte_statistics_test.csv', index=False)\n",
    "\n",
    "print(f\"Generated {len(stats_data)} plots and saved statistics to CSV\")\n"
   ],
   "id": "c05bbfa715c606ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 plots and saved statistics to CSV\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Monthly",
   "id": "516636d1ce361e24"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### time series",
   "id": "41a393cc3f1bf91c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "final_result_cleaned.head()",
   "id": "8a1e8ad103ae1281"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import os\n",
    "\n",
    "# Ensure the plots directory exists\n",
    "os.makedirs('downstream/all/monthly/subplot_q_delta_wte_monthly', exist_ok=True)\n",
    "\n",
    "# Prepare a list to collect statistical data for CSV\n",
    "stats_data = []\n",
    "\n",
    "# Assuming final_result_cleaned is already loaded as a DataFrame\n",
    "# Group by gage_id\n",
    "grouped = final_result_cleaned.groupby('gage_id')\n",
    "\n",
    "# Iterate over each group\n",
    "for gage_id, group in grouped:\n",
    "    # Drop NaN values (changed from 'q' to 'delta_q')\n",
    "    group = group.dropna(subset=['delta_wte', 'date', 'delta_q'])\n",
    "\n",
    "    # Convert date to datetime format\n",
    "    group['date'] = pd.to_datetime(group['date'])\n",
    "\n",
    "    # Extract month from date\n",
    "    group['month'] = group['date'].dt.month\n",
    "    group['month_name'] = group['date'].dt.strftime('%B')\n",
    "\n",
    "    # Sort by date to ensure the line plot is correct\n",
    "    group = group.sort_values('date')\n",
    "\n",
    "    # Get unique months in the data\n",
    "    unique_months = sorted(group['month'].unique())\n",
    "\n",
    "    # Skip if no monthly data\n",
    "    if len(unique_months) == 0:\n",
    "        continue\n",
    "\n",
    "    # Create plots for each month\n",
    "    for month in unique_months:\n",
    "        # Filter data for current month\n",
    "        monthly_data = group[group['month'] == month].copy()\n",
    "        month_name = monthly_data['month_name'].iloc[0]\n",
    "\n",
    "        # Skip if insufficient data for this month\n",
    "        if len(monthly_data) < 2:\n",
    "            continue\n",
    "\n",
    "        # Create subplots (Delta Q on top, Delta WTE on bottom)\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "        # Plot delta_q vs. date on the top subplot (changed from q)\n",
    "        ax1.scatter(monthly_data['date'], monthly_data['delta_q'], color='orange', label='Delta Q (cfs)', alpha=0.6)\n",
    "\n",
    "        # Perform linear regression for delta_q (changed from q)\n",
    "        if len(monthly_data) > 1 and len(monthly_data['date'].unique()) > 1:\n",
    "            monthly_data['date_numeric'] = monthly_data['date'].map(pd.Timestamp.toordinal)\n",
    "            slope_delta_q, intercept_delta_q, r_value_delta_q, p_value_delta_q, std_err_delta_q = linregress(\n",
    "                monthly_data['date_numeric'], monthly_data['delta_q']\n",
    "            )\n",
    "\n",
    "            # Plot the regression line for delta_q\n",
    "            ax1.plot(monthly_data['date'],\n",
    "                    intercept_delta_q + slope_delta_q * monthly_data['date_numeric'],\n",
    "                    'r', label='Fitted line for Delta Q')\n",
    "\n",
    "            # Prepare legend text for delta_q\n",
    "            legend_text_delta_q = (\n",
    "                f\"Delta Q Points: {len(monthly_data)}\\n\"\n",
    "                f\"Slope Delta Q: {slope_delta_q:.6f}\\n\"\n",
    "                f\"R² Delta Q: {r_value_delta_q ** 2:.2f}\\n\"\n",
    "                f\"P-value Delta Q: {p_value_delta_q:.4f}\"\n",
    "            )\n",
    "        else:\n",
    "            slope_delta_q = r_value_delta_q = p_value_delta_q = None\n",
    "            legend_text_delta_q = (\n",
    "                f\"Delta Q Points: {len(monthly_data)}\\n\"\n",
    "                \"Insufficient data for regression\"\n",
    "            )\n",
    "\n",
    "        ax1.set_ylabel('Delta Q (cfs)')\n",
    "        ax1.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "        # Add a custom legend with statistical data for delta_q\n",
    "        ax1.text(\n",
    "            0.05, 0.95,\n",
    "            legend_text_delta_q,\n",
    "            transform=ax1.transAxes,\n",
    "            fontsize=10,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "        )\n",
    "\n",
    "        # Plot delta_wte vs. date on the bottom subplot\n",
    "        ax2.scatter(monthly_data['date'], monthly_data['delta_wte'], color='blue', label='Delta WTE', alpha=0.6)\n",
    "\n",
    "        # Perform linear regression for delta_wte\n",
    "        if len(monthly_data) > 1 and len(monthly_data['date'].unique()) > 1:\n",
    "            slope_wte, intercept_wte, r_value_wte, p_value_wte, std_err_wte = linregress(\n",
    "                monthly_data['date_numeric'], monthly_data['delta_wte']\n",
    "            )\n",
    "\n",
    "            # Plot the regression line for delta_wte\n",
    "            ax2.plot(monthly_data['date'],\n",
    "                    intercept_wte + slope_wte * monthly_data['date_numeric'],\n",
    "                    'r', label='Fitted line for Delta WTE')\n",
    "\n",
    "            # Collect statistics (updated variable names)\n",
    "            stats_data.append({\n",
    "                'gage_id': gage_id,\n",
    "                'month': month,\n",
    "                'month_name': month_name,\n",
    "                'num_wells': monthly_data['well_id'].nunique(),\n",
    "                'num_measurements': len(monthly_data),\n",
    "                'slope_delta_q': slope_delta_q,\n",
    "                'r_squared_delta_q': r_value_delta_q ** 2 if r_value_delta_q is not None else None,\n",
    "                'p_value_delta_q': p_value_delta_q,\n",
    "                'slope_wte': slope_wte,\n",
    "                'r_squared_wte': r_value_wte ** 2,\n",
    "                'p_value_wte': p_value_wte\n",
    "            })\n",
    "\n",
    "            # Prepare legend text for delta_wte\n",
    "            legend_text_wte = (\n",
    "                f\"Wells: {monthly_data['well_id'].nunique()}\\n\"\n",
    "                f\"Measurements: {len(monthly_data)}\\n\"\n",
    "                f\"Slope WTE: {slope_wte:.6f}\\n\"\n",
    "                f\"R² WTE: {r_value_wte ** 2:.2f}\\n\"\n",
    "                f\"P-value WTE: {p_value_wte:.4f}\"\n",
    "            )\n",
    "        else:\n",
    "            legend_text_wte = (\n",
    "                f\"Wells: {monthly_data['well_id'].nunique()}\\n\"\n",
    "                f\"Measurements: {len(monthly_data)}\\n\"\n",
    "                \"Insufficient data for regression\"\n",
    "            )\n",
    "\n",
    "        ax2.set_ylabel('Delta WTE (ft)')\n",
    "        ax2.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "        # Add a custom legend with statistical data for delta_wte\n",
    "        ax2.text(\n",
    "            0.05, 0.95,\n",
    "            legend_text_wte,\n",
    "            transform=ax2.transAxes,\n",
    "            fontsize=10,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "        )\n",
    "\n",
    "        # Set a single title for both subplots, closer to the plots (updated title)\n",
    "        fig.suptitle(f'Gage ID: {gage_id} - {month_name} - Delta Q and Delta WTE vs. Time',\n",
    "                    fontsize=16, y=0.92)\n",
    "\n",
    "        # Format the date axis\n",
    "        ax2.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m-%d'))\n",
    "        ax2.xaxis.set_major_locator(plt.matplotlib.dates.AutoDateLocator())\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        # Save the plot (updated filename)\n",
    "        plt.savefig(f'downstream/all/monthly/subplot_q_delta_wte_monthly/gage_{gage_id}_{month:02d}_{month_name}.png',\n",
    "                   bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# Export statistics to CSV (updated filename)\n",
    "if stats_data:\n",
    "    stats_df = pd.DataFrame(stats_data)\n",
    "    stats_df.to_csv('downstream/all/monthly/delta_q_delta_wte_monthly_statistics.csv', index=False)\n",
    "\n",
    "    # Calculate monthly statistics (updated variable names)\n",
    "    print(\"Monthly Summary Statistics:\")\n",
    "    for month_name in sorted(stats_df['month_name'].unique()):\n",
    "        month_data = stats_df[stats_df['month_name'] == month_name]\n",
    "\n",
    "        print(f\"\\n{month_name}:\")\n",
    "        print(f\"  Number of gages: {len(month_data)}\")\n",
    "        print(f\"  Average R² Delta Q: {month_data['r_squared_delta_q'].mean():.3f}\")\n",
    "        print(f\"  Average R² WTE: {month_data['r_squared_wte'].mean():.3f}\")\n",
    "        print(f\"  Positive slope Delta Q: {(month_data['slope_delta_q'] > 0).mean() * 100:.1f}%\")\n",
    "        print(f\"  Positive slope WTE: {(month_data['slope_wte'] > 0).mean() * 100:.1f}%\")\n",
    "\n",
    "    # Overall statistics (updated variable names)\n",
    "    overall_positive_delta_q = (stats_df['slope_delta_q'] > 0).mean() * 100\n",
    "    overall_positive_wte = (stats_df['slope_wte'] > 0).mean() * 100\n",
    "\n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"Total gage-month combinations: {len(stats_df)}\")\n",
    "    print(f\"Percentage of positive slopes for Delta Q: {overall_positive_delta_q:.2f}%\")\n",
    "    print(f\"Percentage of positive slopes for Delta WTE: {overall_positive_wte:.2f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"No statistical data collected - insufficient data for regression analysis\")\n"
   ],
   "id": "29dcea8d44da15ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### scatter plots",
   "id": "42b9d77ed36a322e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:31:11.918037Z",
     "start_time": "2025-08-13T17:31:00.266277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import linregress\n",
    "import os\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs('../reports/figures/monthly/scatter_plots_delta_q_vs_delta_wte', exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "final_result_cleaned = pd.read_csv('../data/features/q_buffer2_pair_delta_30m.csv')\n",
    "gage_class = pd.read_excel('../data/raw/streamflow/GAGES-II_ref_non_ref.xlsx')\n",
    "\n",
    "# Merge gage classification information\n",
    "final_result_cleaned['gage_id'] = final_result_cleaned['gage_id'].astype(str)\n",
    "gage_class['STAID'] = gage_class['STAID'].astype(str)\n",
    "\n",
    "final_result_cleaned = final_result_cleaned.merge(\n",
    "    gage_class[['STAID', 'CLASS']],\n",
    "    left_on='gage_id',\n",
    "    right_on='STAID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "final_result_cleaned.drop('STAID', axis=1, inplace=True)\n",
    "final_result_cleaned.rename(columns={'CLASS': 'class'}, inplace=True)\n",
    "\n",
    "# Add month information\n",
    "final_result_cleaned['date'] = pd.to_datetime(final_result_cleaned['date'])\n",
    "final_result_cleaned['month'] = final_result_cleaned['date'].dt.month\n",
    "\n",
    "# Month name mapping\n",
    "month_names = {\n",
    "    1: 'January', 2: 'February', 3: 'March', 4: 'April',\n",
    "    5: 'May', 6: 'June', 7: 'July', 8: 'August',\n",
    "    9: 'September', 10: 'October', 11: 'November', 12: 'December'\n",
    "}\n",
    "\n",
    "# Prepare statistics collection\n",
    "stats_data = []\n",
    "\n",
    "# Group by gage_id\n",
    "grouped = final_result_cleaned.groupby('gage_id')\n",
    "\n",
    "# Create monthly scatter plots for each gage\n",
    "for gage_id, group in grouped:\n",
    "    group = group.dropna(subset=['delta_wte', 'delta_q'])\n",
    "\n",
    "    # Check if enough data is available\n",
    "    if len(group) < 2:\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Get available months for this gage\n",
    "    available_months = sorted(group['month'].unique())\n",
    "\n",
    "    # Adjust subplot layout based on number of months\n",
    "    if len(available_months) <= 4:\n",
    "        rows, cols = 2, 2\n",
    "    elif len(available_months) <= 6:\n",
    "        rows, cols = 2, 3\n",
    "    elif len(available_months) <= 9:\n",
    "        rows, cols = 3, 3\n",
    "    else:\n",
    "        rows, cols = 3, 4\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 12))\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    elif cols == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Map class display names\n",
    "    if 'class' in group.columns and not group['class'].isna().all():\n",
    "        class_display = group['class'].iloc[0]\n",
    "        if class_display == 'Non-ref':\n",
    "            class_display = 'Unregulated'\n",
    "        elif class_display == 'Ref':\n",
    "            class_display = 'Regulated'\n",
    "    else:\n",
    "        class_display = 'Unknown'\n",
    "\n",
    "    # Create scatter plots for each month\n",
    "    for idx, month in enumerate(available_months):\n",
    "        if idx >= len(axes):\n",
    "            break\n",
    "\n",
    "        ax = axes[idx]\n",
    "        month_data = group[group['month'] == month]\n",
    "\n",
    "        if len(month_data) == 0:\n",
    "            ax.set_visible(False)\n",
    "            continue\n",
    "\n",
    "        # Plot scatter with different colors for each well\n",
    "        sns.scatterplot(\n",
    "            data=month_data,\n",
    "            x='delta_wte',\n",
    "            y='delta_q',\n",
    "            hue='well_id',\n",
    "            palette='viridis',\n",
    "            edgecolor='none',\n",
    "            legend=False,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        legend_text = \"\"\n",
    "\n",
    "        # Perform linear regression if enough data points\n",
    "        if len(month_data) >= 2 and len(month_data['delta_wte'].unique()) > 1:\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(\n",
    "                month_data['delta_wte'], month_data['delta_q']\n",
    "            )\n",
    "\n",
    "            # Plot regression line\n",
    "            delta_wte_range = pd.Series(month_data['delta_wte'].unique()).sort_values()\n",
    "            ax.plot(delta_wte_range, intercept + slope * delta_wte_range, 'r', linewidth=2)\n",
    "\n",
    "            # Collect statistics\n",
    "            stats_data.append({\n",
    "                'gage_id': gage_id,\n",
    "                'month': month,\n",
    "                'month_name': month_names[month],\n",
    "                'num_wells': month_data['well_id'].nunique(),\n",
    "                'num_measurements': len(month_data),\n",
    "                'slope': slope,\n",
    "                'intercept': intercept,\n",
    "                'r_squared': r_value ** 2,\n",
    "                'p_value': p_value,\n",
    "                'class': class_display\n",
    "            })\n",
    "\n",
    "            legend_text = (\n",
    "                f\"Wells: {month_data['well_id'].nunique()}\\n\"\n",
    "                f\"Measurements: {len(month_data)}\\n\"\n",
    "                f\"Slope: {slope:.2f}\\n\"\n",
    "                f\"R²: {r_value ** 2:.2f}\\n\"\n",
    "                f\"p-value: {p_value:.4f}\"\n",
    "            )\n",
    "        else:\n",
    "            if len(month_data['delta_wte'].unique()) == 1:\n",
    "                legend_text = (\n",
    "                    f\"Wells: {month_data['well_id'].nunique()}\\n\"\n",
    "                    f\"Measurements: {len(month_data)}\\n\"\n",
    "                    \"All delta_wte identical\\nNo regression\"\n",
    "                )\n",
    "            else:\n",
    "                legend_text = (\n",
    "                    f\"Wells: {month_data['well_id'].nunique()}\\n\"\n",
    "                    f\"Measurements: {len(month_data)}\\n\"\n",
    "                    \"Not enough data\"\n",
    "                )\n",
    "\n",
    "        # Set subplot labels and title\n",
    "        ax.set_title(f'{month_names[month]}', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Delta WTE (ft)', fontsize=10)\n",
    "        ax.set_ylabel('Delta Q (cfs)', fontsize=10)\n",
    "\n",
    "        # Add grid\n",
    "        ax.yaxis.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "        ax.xaxis.grid(False)\n",
    "        ax.set_facecolor('white')\n",
    "\n",
    "        # Add statistics text box\n",
    "        ax.text(\n",
    "            0.98, 0.95,\n",
    "            legend_text,\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=8,\n",
    "            ha='right',\n",
    "            va='top',\n",
    "            linespacing=1.2,\n",
    "            bbox=dict(\n",
    "                facecolor='white',\n",
    "                edgecolor='black',\n",
    "                alpha=0.75,\n",
    "                boxstyle='square,pad=0.3'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(available_months), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "\n",
    "    # Set main title\n",
    "    fig.suptitle(f'Gage ID: {gage_id} - Class: {class_display}\\nDelta Q vs Delta WTE by Month',\n",
    "                 fontsize=16, fontweight='bold', y=0.95)\n",
    "\n",
    "    # Adjust layout and save plot\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "    plt.savefig(f'../reports/figures/monthly/scatter_plots_delta_q_vs_delta_wte/gage_{gage_id}_monthly.png',\n",
    "                bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Export statistics\n",
    "if stats_data:\n",
    "    stats_df = pd.DataFrame(stats_data)\n",
    "    stats_df.to_csv('../reports/figures/monthly/scatter_delta_q_vs_delta_wte_monthly_statistics.csv', index=False)\n",
    "\n",
    "    # Calculate summary statistics\n",
    "    print(f\"Generated monthly scatter plots for {len(grouped)} gages\")\n",
    "    print(f\"Total monthly analyses: {len(stats_data)}\")\n",
    "\n",
    "    # Monthly statistics\n",
    "    monthly_summary = stats_df.groupby('month_name').agg({\n",
    "        'gage_id': 'count',\n",
    "        'slope': ['mean', 'std'],\n",
    "        'r_squared': ['mean', 'std'],\n",
    "        'p_value': lambda x: (x < 0.05).sum()\n",
    "    }).round(4)\n",
    "\n",
    "    print(\"\\nMonthly Summary:\")\n",
    "    print(monthly_summary)\n",
    "\n",
    "    # Class statistics\n",
    "    if 'class' in stats_df.columns:\n",
    "        class_summary = stats_df.groupby('class').agg({\n",
    "            'gage_id': 'count',\n",
    "            'slope': ['mean', 'std'],\n",
    "            'r_squared': ['mean', 'std'],\n",
    "            'p_value': lambda x: (x < 0.05).sum()\n",
    "        }).round(4)\n",
    "\n",
    "        print(\"\\nClass Summary:\")\n",
    "        print(class_summary)\n",
    "else:\n",
    "    print(\"No valid data found for analysis\")\n"
   ],
   "id": "e2af487d42a7c116",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated monthly scatter plots for 4 gages\n",
      "Total monthly analyses: 48\n",
      "\n",
      "Monthly Summary:\n",
      "           gage_id   slope         r_squared          p_value\n",
      "             count    mean     std      mean     std <lambda>\n",
      "month_name                                                   \n",
      "April            4  1.6399  3.1985    0.2154  0.3658        3\n",
      "August           4  3.1640  4.8014    0.2284  0.3702        4\n",
      "December         4 -1.0856  3.8309    0.2293  0.3893        4\n",
      "February         4  0.1858  1.4867    0.2372  0.3894        3\n",
      "January          4 -0.7930  3.1519    0.2393  0.3829        4\n",
      "July             4  1.5059  1.9849    0.2125  0.3709        4\n",
      "June             4  0.4326  0.5259    0.1809  0.3420        3\n",
      "March            4  2.2114  4.3505    0.2700  0.3813        3\n",
      "May              4 -0.7865  1.3304    0.1872  0.3493        2\n",
      "November         4 -2.9164  6.9465    0.2221  0.3886        4\n",
      "October          4 -2.8222  8.5787    0.2266  0.3507        4\n",
      "September        4  1.4824  2.2090    0.1982  0.3719        3\n",
      "\n",
      "Class Summary:\n",
      "            gage_id   slope         r_squared          p_value\n",
      "              count    mean     std      mean     std <lambda>\n",
      "class                                                         \n",
      "Unregulated      48  0.1849  4.1213    0.2206  0.3259       41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import linregress\n",
    "import os\n",
    "\n",
    "# Ensure required packages are installed\n",
    "!pip install openpyxl"
   ],
   "id": "f0f5d3e73b1121e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load gage classification data\n",
    "gage_class = pd.read_excel('data/GAGES-II_ref_non_ref.xlsx')\n",
    "gage_class['STAID'] = gage_class['STAID'].astype(str)"
   ],
   "id": "11532d462f05ce2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load GSL basin gage data\n",
    "gage_in_gslb = pd.read_csv('shp/gsl_nwm_gage.csv')\n",
    "gage_in_gslb['id'] = gage_in_gslb['id'].astype(str)"
   ],
   "id": "453e7a948d8d6752"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Merge gage data with classifications\n",
    "gage_in_gslb_with_class = gage_in_gslb.merge(\n",
    "    gage_class[['STAID', 'CLASS']],\n",
    "    left_on='id',\n",
    "    right_on='STAID',\n",
    "    how='left'\n",
    ").drop('STAID', axis=1).rename(columns={'CLASS': 'class'})"
   ],
   "id": "7beb4890ada99363"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load delta metrics data\n",
    "final_result_cleaned = pd.read_csv('downstream/all/q_buffer2_pair_delta_30m.csv')\n",
    "final_result_cleaned['date'] = pd.to_datetime(final_result_cleaned['date'])"
   ],
   "id": "f01c56ed1edca20a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create output directories for plots\n",
    "os.makedirs('../reports/figures/monthly/scatter_plots_delta_q_vs_delta_wte/subplot_q_delta_wte_monthly', exist_ok=True)"
   ],
   "id": "b966d3fab2458b73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define month mapping for better readability\n",
    "MONTH_NAMES = {\n",
    "    1: 'January', 2: 'February', 3: 'March', 4: 'April',\n",
    "    5: 'May', 6: 'June', 7: 'July', 8: 'August',\n",
    "    9: 'September', 10: 'October', 11: 'November', 12: 'December'\n",
    "}"
   ],
   "id": "beedae04ca812cb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Simple monthly statistical report - Positive slope percentage and R²\n",
    "def generate_simple_monthly_report(stats_df):\n",
    "    \"\"\"\n",
    "    Generate a simple monthly report showing percentage of positive slopes and R² values\n",
    "    \"\"\"\n",
    "    print(\"MONTHLY STATISTICAL REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Month order for proper chronological display\n",
    "    month_order = ['January', 'February', 'March', 'April', 'May', 'June',\n",
    "                   'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "    # Create summary for each month\n",
    "    monthly_results = []\n",
    "\n",
    "    for month in month_order:\n",
    "        if month in stats_df['month_name'].values:\n",
    "            month_data = stats_df[stats_df['month_name'] == month]\n",
    "\n",
    "            # Calculate statistics\n",
    "            total_records = len(month_data)\n",
    "            positive_slopes = (month_data['slope'] > 0).sum()\n",
    "            positive_percentage = (positive_slopes / total_records) * 100\n",
    "            mean_r_squared = month_data['r_squared'].mean()\n",
    "\n",
    "            monthly_results.append({\n",
    "                'Month': month,\n",
    "                'Total_Records': total_records,\n",
    "                'Positive_Slopes_Percentage': positive_percentage,\n",
    "                'Mean_R_Squared': mean_r_squared\n",
    "            })\n",
    "\n",
    "            print(f\"{month:12} | Records: {total_records:3d} | Positive Slopes: {positive_percentage:5.1f}% | Mean R²: {mean_r_squared:.3f}\")\n",
    "\n",
    "    # Overall statistics\n",
    "    total_all = len(stats_df)\n",
    "    positive_all = (stats_df['slope'] > 0).sum()\n",
    "    positive_pct_all = (positive_all / total_all) * 100\n",
    "    mean_r2_all = stats_df['r_squared'].mean()\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'OVERALL':12} | Records: {total_all:3d} | Positive Slopes: {positive_pct_all:5.1f}% | Mean R²: {mean_r2_all:.3f}\")\n",
    "\n",
    "    # Export to CSV\n",
    "    results_df = pd.DataFrame(monthly_results)\n",
    "    results_df.to_csv('downstream/all/monthly/simple_monthly_report.csv', index=False)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Load monthly statistics and generate report\n",
    "monthly_stats = pd.read_csv('downstream/all/monthly/scatter_delta_q_vs_delta_wte_monthly_statistics.csv')\n",
    "simple_report = generate_simple_monthly_report(monthly_stats)\n"
   ],
   "id": "3602bde3cecafa4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Seasonal",
   "id": "349b431ed739b2f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### time series",
   "id": "13cf8368619bcee4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import os\n",
    "\n",
    "# Ensure the plots directory exists\n",
    "os.makedirs('downstream/all/seasonal/subplot_delta_q_delta_wte_seasonal', exist_ok=True)\n",
    "\n",
    "# Prepare a list to collect statistical data for CSV\n",
    "stats_data = []\n",
    "\n",
    "# Define season mapping function\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Fall'\n",
    "\n",
    "# Assuming final_result_cleaned is already loaded as a DataFrame\n",
    "# Group by gage_id\n",
    "grouped = final_result_cleaned.groupby('gage_id')\n",
    "\n",
    "# Iterate over each group\n",
    "for gage_id, group in grouped:\n",
    "    # Drop NaN values (changed from 'q' to 'delta_q')\n",
    "    group = group.dropna(subset=['delta_wte', 'date', 'delta_q'])\n",
    "\n",
    "    # Convert date to datetime format\n",
    "    group['date'] = pd.to_datetime(group['date'])\n",
    "\n",
    "    # Extract month and season from date\n",
    "    group['month'] = group['date'].dt.month\n",
    "    group['season'] = group['month'].apply(get_season)\n",
    "\n",
    "    # Sort by date to ensure the line plot is correct\n",
    "    group = group.sort_values('date')\n",
    "\n",
    "    # Get unique seasons in the data\n",
    "    unique_seasons = sorted(group['season'].unique())\n",
    "\n",
    "    # Skip if no seasonal data\n",
    "    if len(unique_seasons) == 0:\n",
    "        continue\n",
    "\n",
    "    # Create plots for each season\n",
    "    for season in unique_seasons:\n",
    "        # Filter data for current season\n",
    "        seasonal_data = group[group['season'] == season].copy()\n",
    "\n",
    "        # Skip if insufficient data for this season\n",
    "        if len(seasonal_data) < 2:\n",
    "            continue\n",
    "\n",
    "        # Create subplots (Delta Q on top, Delta WTE on bottom)\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "        # Plot delta_q vs. date on the top subplot (changed from q)\n",
    "        ax1.scatter(seasonal_data['date'], seasonal_data['delta_q'], color='orange', label='Delta Q (cfs)', alpha=0.6)\n",
    "\n",
    "        # Perform linear regression for delta_q (changed from q)\n",
    "        if len(seasonal_data) > 1 and len(seasonal_data['date'].unique()) > 1:\n",
    "            seasonal_data['date_numeric'] = seasonal_data['date'].map(pd.Timestamp.toordinal)\n",
    "            slope_delta_q, intercept_delta_q, r_value_delta_q, p_value_delta_q, std_err_delta_q = linregress(\n",
    "                seasonal_data['date_numeric'], seasonal_data['delta_q']\n",
    "            )\n",
    "\n",
    "            # Plot the regression line for delta_q\n",
    "            ax1.plot(seasonal_data['date'],\n",
    "                    intercept_delta_q + slope_delta_q * seasonal_data['date_numeric'],\n",
    "                    'r', label='Fitted line for Delta Q')\n",
    "\n",
    "            # Prepare legend text for delta_q\n",
    "            legend_text_delta_q = (\n",
    "                f\"Delta Q Points: {len(seasonal_data)}\\n\"\n",
    "                f\"Slope Delta Q: {slope_delta_q:.6f}\\n\"\n",
    "                f\"R² Delta Q: {r_value_delta_q ** 2:.2f}\\n\"\n",
    "                f\"P-value Delta Q: {p_value_delta_q:.4f}\"\n",
    "            )\n",
    "        else:\n",
    "            slope_delta_q = r_value_delta_q = p_value_delta_q = None\n",
    "            legend_text_delta_q = (\n",
    "                f\"Delta Q Points: {len(seasonal_data)}\\n\"\n",
    "                \"Insufficient data for regression\"\n",
    "            )\n",
    "\n",
    "        ax1.set_ylabel('Delta Q (cfs)')\n",
    "        ax1.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "        # Add a custom legend with statistical data for delta_q\n",
    "        ax1.text(\n",
    "            0.05, 0.95,\n",
    "            legend_text_delta_q,\n",
    "            transform=ax1.transAxes,\n",
    "            fontsize=10,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "        )\n",
    "\n",
    "        # Plot delta_wte vs. date on the bottom subplot\n",
    "        ax2.scatter(seasonal_data['date'], seasonal_data['delta_wte'], color='blue', label='Delta WTE', alpha=0.6)\n",
    "\n",
    "        # Perform linear regression for delta_wte\n",
    "        if len(seasonal_data) > 1 and len(seasonal_data['date'].unique()) > 1:\n",
    "            slope_wte, intercept_wte, r_value_wte, p_value_wte, std_err_wte = linregress(\n",
    "                seasonal_data['date_numeric'], seasonal_data['delta_wte']\n",
    "            )\n",
    "\n",
    "            # Plot the regression line for delta_wte\n",
    "            ax2.plot(seasonal_data['date'],\n",
    "                    intercept_wte + slope_wte * seasonal_data['date_numeric'],\n",
    "                    'r', label='Fitted line for Delta WTE')\n",
    "\n",
    "            # Collect statistics (updated variable names)\n",
    "            stats_data.append({\n",
    "                'gage_id': gage_id,\n",
    "                'season': season,\n",
    "                'num_wells': seasonal_data['well_id'].nunique(),\n",
    "                'num_measurements': len(seasonal_data),\n",
    "                'slope_delta_q': slope_delta_q,\n",
    "                'r_squared_delta_q': r_value_delta_q ** 2 if r_value_delta_q is not None else None,\n",
    "                'p_value_delta_q': p_value_delta_q,\n",
    "                'slope_wte': slope_wte,\n",
    "                'r_squared_wte': r_value_wte ** 2,\n",
    "                'p_value_wte': p_value_wte\n",
    "            })\n",
    "\n",
    "            # Prepare legend text for delta_wte\n",
    "            legend_text_wte = (\n",
    "                f\"Wells: {seasonal_data['well_id'].nunique()}\\n\"\n",
    "                f\"Measurements: {len(seasonal_data)}\\n\"\n",
    "                f\"Slope WTE: {slope_wte:.6f}\\n\"\n",
    "                f\"R² WTE: {r_value_wte ** 2:.2f}\\n\"\n",
    "                f\"P-value WTE: {p_value_wte:.4f}\"\n",
    "            )\n",
    "        else:\n",
    "            legend_text_wte = (\n",
    "                f\"Wells: {seasonal_data['well_id'].nunique()}\\n\"\n",
    "                f\"Measurements: {len(seasonal_data)}\\n\"\n",
    "                \"Insufficient data for regression\"\n",
    "            )\n",
    "\n",
    "        ax2.set_ylabel('Delta WTE (ft)')\n",
    "        ax2.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "        # Add a custom legend with statistical data for delta_wte\n",
    "        ax2.text(\n",
    "            0.05, 0.95,\n",
    "            legend_text_wte,\n",
    "            transform=ax2.transAxes,\n",
    "            fontsize=10,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.5)\n",
    "        )\n",
    "\n",
    "        # Set a single title for both subplots, closer to the plots (updated title)\n",
    "        fig.suptitle(f'Gage ID: {gage_id} - {season} - Delta Q and Delta WTE vs. Time',\n",
    "                    fontsize=16, y=0.92)\n",
    "\n",
    "        # Format the date axis\n",
    "        ax2.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m-%d'))\n",
    "        ax2.xaxis.set_major_locator(plt.matplotlib.dates.AutoDateLocator())\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "        # Save the plot (updated filename and path)\n",
    "        plt.savefig(f'downstream/all/seasonal/subplot_delta_q_delta_wte_seasonal/gage_{gage_id}_{season}.png',\n",
    "                   bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# Export statistics to CSV (updated filename)\n",
    "if stats_data:\n",
    "    stats_df = pd.DataFrame(stats_data)\n",
    "    stats_df.to_csv('downstream/all/seasonal/delta_q_delta_wte_seasonal_statistics.csv', index=False)\n",
    "\n",
    "    # Calculate seasonal statistics (updated variable names)\n",
    "    print(\"Seasonal Summary Statistics:\")\n",
    "    for season in sorted(stats_df['season'].unique()):\n",
    "        season_data = stats_df[stats_df['season'] == season]\n",
    "\n",
    "        print(f\"\\n{season}:\")\n",
    "        print(f\"  Number of gages: {len(season_data)}\")\n",
    "        print(f\"  Average R² Delta Q: {season_data['r_squared_delta_q'].mean():.3f}\")\n",
    "        print(f\"  Average R² WTE: {season_data['r_squared_wte'].mean():.3f}\")\n",
    "        print(f\"  Positive slope Delta Q: {(season_data['slope_delta_q'] > 0).mean() * 100:.1f}%\")\n",
    "        print(f\"  Positive slope WTE: {(season_data['slope_wte'] > 0).mean() * 100:.1f}%\")\n",
    "\n",
    "    # Overall statistics (updated variable names)\n",
    "    overall_positive_delta_q = (stats_df['slope_delta_q'] > 0).mean() * 100\n",
    "    overall_positive_wte = (stats_df['slope_wte'] > 0).mean() * 100\n",
    "\n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"Total gage-season combinations: {len(stats_df)}\")\n",
    "    print(f\"Percentage of positive slopes for Delta Q: {overall_positive_delta_q:.2f}%\")\n",
    "    print(f\"Percentage of positive slopes for Delta WTE: {overall_positive_wte:.2f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"No statistical data collected - insufficient data for regression analysis\")\n"
   ],
   "id": "1f4783b84fba073f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## scatter plots",
   "id": "14f920f43fe51f65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:35:24.665989Z",
     "start_time": "2025-08-13T17:34:43.731444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import linregress\n",
    "import os\n",
    "\n",
    "# Ensure the plots directory exists\n",
    "os.makedirs('../reports/figures/seasonal/delta_q_vs_delta_wte_by_gage_seasonal', exist_ok=True)\n",
    "\n",
    "# Define season mapping function\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Fall'\n",
    "\n",
    "# Load the data\n",
    "final_result_cleaned = pd.read_csv('../data/features/q_buffer2_pair_delta_30m.csv')\n",
    "\n",
    "# Re-merge with gage_class to ensure 'class' column exists\n",
    "final_result_cleaned['gage_id'] = final_result_cleaned['gage_id'].astype(str)\n",
    "gage_class['STAID'] = gage_class['STAID'].astype(str)\n",
    "\n",
    "# Merge to add CLASS column\n",
    "final_result_cleaned = final_result_cleaned.merge(\n",
    "    gage_class[['STAID', 'CLASS']],\n",
    "    left_on='gage_id',\n",
    "    right_on='STAID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Clean up and rename\n",
    "final_result_cleaned.drop('STAID', axis=1, inplace=True)\n",
    "final_result_cleaned.rename(columns={'CLASS': 'class'}, inplace=True)\n",
    "\n",
    "# Prepare a list to collect statistical data for CSV\n",
    "stats_data = []\n",
    "\n",
    "# Convert date to datetime and extract season information\n",
    "final_result_cleaned['date'] = pd.to_datetime(final_result_cleaned['date'])\n",
    "final_result_cleaned['month'] = final_result_cleaned['date'].dt.month\n",
    "final_result_cleaned['season'] = final_result_cleaned['month'].apply(get_season)\n",
    "\n",
    "# Group by gage_id\n",
    "grouped = final_result_cleaned.groupby('gage_id')\n",
    "\n",
    "# Iterate over each gage\n",
    "for gage_id, gage_group in grouped:\n",
    "    # Get unique seasons for this gage\n",
    "    unique_seasons = sorted(gage_group['season'].unique())\n",
    "\n",
    "    # Skip if no seasonal data\n",
    "    if len(unique_seasons) == 0:\n",
    "        continue\n",
    "\n",
    "    # Create plots for each season\n",
    "    for season in unique_seasons:\n",
    "        # Filter data for current season\n",
    "        seasonal_data = gage_group[gage_group['season'] == season].copy()\n",
    "\n",
    "        # Drop NaN values\n",
    "        seasonal_data = seasonal_data.dropna(subset=['delta_wte', 'delta_q'])\n",
    "\n",
    "        # Skip if not enough data points\n",
    "        if len(seasonal_data) < 2:\n",
    "            continue\n",
    "\n",
    "        # Convert delta_q to acre-ft/year\n",
    "        seasonal_data['delta_q_acre_ft_year'] = seasonal_data['delta_q'] * 365.25\n",
    "\n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Scatter plot with different colors for different wells\n",
    "        sns.scatterplot(\n",
    "            x='delta_wte',\n",
    "            y='delta_q_acre_ft_year',\n",
    "            data=seasonal_data,\n",
    "            hue='well_id',\n",
    "            palette='viridis',\n",
    "            alpha=0.6,\n",
    "            s=50,\n",
    "            legend=False  # We'll create our own legend\n",
    "        )\n",
    "\n",
    "        # Perform linear regression if there's variation in delta_wte\n",
    "        if len(seasonal_data['delta_wte'].unique()) > 1:\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(\n",
    "                seasonal_data['delta_wte'], seasonal_data['delta_q_acre_ft_year']\n",
    "            )\n",
    "\n",
    "            # Plot the regression line\n",
    "            sns.regplot(\n",
    "                x='delta_wte',\n",
    "                y='delta_q_acre_ft_year',\n",
    "                data=seasonal_data,\n",
    "                scatter=False,\n",
    "                color='red',\n",
    "                line_kws={'linewidth': 2}\n",
    "            )\n",
    "\n",
    "            # Collect statistics\n",
    "            stats_data.append({\n",
    "                'gage_id': gage_id,\n",
    "                'season': season,\n",
    "                'num_wells': seasonal_data['well_id'].nunique(),\n",
    "                'num_measurements': len(seasonal_data),\n",
    "                'slope': slope,\n",
    "                'intercept': intercept,\n",
    "                'r_squared': r_value ** 2,\n",
    "                'p_value': p_value,\n",
    "                'std_err': std_err,\n",
    "                'class': seasonal_data['class'].iloc[0] if 'class' in seasonal_data.columns else 'Unknown'\n",
    "            })\n",
    "\n",
    "            # Statistical text\n",
    "            stats_text = (\n",
    "                f\"Wells: {seasonal_data['well_id'].nunique()}\\n\"\n",
    "                f\"Measurements: {len(seasonal_data)}\\n\"\n",
    "                f\"Slope: {slope:.2f} (acre-ft/year)/ft\\n\"\n",
    "                f\"R²: {r_value**2:.3f}\\n\"\n",
    "                f\"P-value: {p_value:.4f}\"\n",
    "            )\n",
    "        else:\n",
    "            stats_text = (\n",
    "                f\"Wells: {seasonal_data['well_id'].nunique()}\\n\"\n",
    "                f\"Measurements: {len(seasonal_data)}\\n\"\n",
    "                \"All delta_wte values identical\\nNo regression line\"\n",
    "            )\n",
    "\n",
    "        # Map class names for display (with safety check)\n",
    "        if 'class' in seasonal_data.columns and not seasonal_data['class'].isna().all():\n",
    "            class_display = seasonal_data['class'].iloc[0]\n",
    "            if class_display == 'Non-ref':\n",
    "                class_display = 'Unregulated'\n",
    "            elif class_display == 'Ref':\n",
    "                class_display = 'Regulated'\n",
    "        else:\n",
    "            class_display = 'Unknown'\n",
    "\n",
    "        # Add title and labels\n",
    "        plt.title(f'Gage {gage_id} - {season} - Class: {class_display}\\nDelta Q (acre-ft/year) vs Delta WTE', fontsize=14)\n",
    "        plt.xlabel('Delta WTE (ft)', fontsize=12)\n",
    "        plt.ylabel('Delta Q (acre-ft/year)', fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # Add statistical text box\n",
    "        plt.text(\n",
    "            0.05, 0.95,\n",
    "            stats_text,\n",
    "            transform=plt.gca().transAxes,\n",
    "            fontsize=10,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, edgecolor='black')\n",
    "        )\n",
    "\n",
    "        # Save the plot\n",
    "        plt.savefig(f'../reports/figures/seasonal/delta_q_vs_delta_wte_by_gage_seasonal/gage_{gage_id}_{season}_delta_q_vs_delta_wte.png',\n",
    "                    bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "# Export statistics to CSV\n",
    "if stats_data:\n",
    "    stats_df = pd.DataFrame(stats_data)\n",
    "    stats_df.to_csv('../reports/figures/seasonal/delta_q_vs_delta_wte_seasonal_statistics.csv', index=False)\n",
    "\n",
    "    # Print summary statistics by season\n",
    "    print(\"Seasonal Summary Statistics:\")\n",
    "    for season in sorted(stats_df['season'].unique()):\n",
    "        season_data = stats_df[stats_df['season'] == season]\n",
    "\n",
    "        print(f\"\\n{season}:\")\n",
    "        print(f\"  Number of gage-season combinations: {len(season_data)}\")\n",
    "        print(f\"  Average R²: {season_data['r_squared'].mean():.3f}\")\n",
    "        print(f\"  Median R²: {season_data['r_squared'].median():.3f}\")\n",
    "        print(f\"  Positive slope percentage: {(season_data['slope'] > 0).mean() * 100:.1f}%\")\n",
    "        print(f\"  Average slope: {season_data['slope'].mean():.2f} (acre-ft/year)/ft\")\n",
    "\n",
    "    # Overall statistics\n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"Total gage-season combinations: {len(stats_df)}\")\n",
    "    print(f\"Average R²: {stats_df['r_squared'].mean():.3f}\")\n",
    "    print(f\"Percentage with positive slope: {(stats_df['slope'] > 0).mean() * 100:.1f}%\")\n",
    "    print(f\"Number of unique gages: {stats_df['gage_id'].nunique()}\")\n",
    "    print(f\"Number of seasons represented: {stats_df['season'].nunique()}\")\n",
    "\n",
    "else:\n",
    "    print(\"No valid data for regression analysis\")\n"
   ],
   "id": "91fbb0e074f0a25e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonal Summary Statistics:\n",
      "\n",
      "Fall:\n",
      "  Number of gage-season combinations: 4\n",
      "  Average R²: 0.196\n",
      "  Median R²: 0.011\n",
      "  Positive slope percentage: 50.0%\n",
      "  Average slope: 33.30 (acre-ft/year)/ft\n",
      "\n",
      "Spring:\n",
      "  Number of gage-season combinations: 4\n",
      "  Average R²: 0.207\n",
      "  Median R²: 0.035\n",
      "  Positive slope percentage: 75.0%\n",
      "  Average slope: 521.59 (acre-ft/year)/ft\n",
      "\n",
      "Summer:\n",
      "  Number of gage-season combinations: 4\n",
      "  Average R²: 0.213\n",
      "  Median R²: 0.043\n",
      "  Positive slope percentage: 75.0%\n",
      "  Average slope: 901.86 (acre-ft/year)/ft\n",
      "\n",
      "Winter:\n",
      "  Number of gage-season combinations: 4\n",
      "  Average R²: 0.233\n",
      "  Median R²: 0.050\n",
      "  Positive slope percentage: 50.0%\n",
      "  Average slope: -178.44 (acre-ft/year)/ft\n",
      "\n",
      "Overall Statistics:\n",
      "Total gage-season combinations: 16\n",
      "Average R²: 0.212\n",
      "Percentage with positive slope: 62.5%\n",
      "Number of unique gages: 4\n",
      "Number of seasons represented: 4\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T17:35:37.070856Z",
     "start_time": "2025-08-13T17:35:36.968259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Simple seasonal statistical report - Positive slope percentage and R²\n",
    "def generate_simple_seasonal_report(stats_df):\n",
    "    \"\"\"\n",
    "    Generate a simple seasonal report showing percentage of positive slopes and R² values\n",
    "    \"\"\"\n",
    "    print(\"SEASONAL STATISTICAL REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Define seasons based on months\n",
    "    def get_season(month_name):\n",
    "        if month_name in ['December', 'January', 'February']:\n",
    "            return 'Winter'\n",
    "        elif month_name in ['March', 'April', 'May']:\n",
    "            return 'Spring'\n",
    "        elif month_name in ['June', 'July', 'August']:\n",
    "            return 'Summer'\n",
    "        elif month_name in ['September', 'October', 'November']:\n",
    "            return 'Fall'\n",
    "        return 'Unknown'\n",
    "\n",
    "    # Add season column if it doesn't exist\n",
    "    if 'season' not in stats_df.columns:\n",
    "        if 'month_name' in stats_df.columns:\n",
    "            stats_df['season'] = stats_df['month_name'].apply(get_season)\n",
    "        else:\n",
    "            # If we only have season column already, use it directly\n",
    "            pass\n",
    "\n",
    "    # Season order for proper display\n",
    "    season_order = ['Spring', 'Summer', 'Fall', 'Winter']\n",
    "\n",
    "    # Create summary for each season\n",
    "    seasonal_results = []\n",
    "\n",
    "    for season in season_order:\n",
    "        if season in stats_df['season'].values:\n",
    "            season_data = stats_df[stats_df['season'] == season]\n",
    "\n",
    "            # Calculate statistics for Delta Q\n",
    "            total_records = len(season_data)\n",
    "            positive_slopes_delta_q = (season_data['slope_delta_q'] > 0).sum()\n",
    "            positive_percentage_delta_q = (positive_slopes_delta_q / total_records) * 100\n",
    "            mean_r_squared_delta_q = season_data['r_squared_delta_q'].mean()\n",
    "\n",
    "            # Calculate statistics for WTE\n",
    "            positive_slopes_wte = (season_data['slope_wte'] > 0).sum()\n",
    "            positive_percentage_wte = (positive_slopes_wte / total_records) * 100\n",
    "            mean_r_squared_wte = season_data['r_squared_wte'].mean()\n",
    "\n",
    "            seasonal_results.append({\n",
    "                'Season': season,\n",
    "                'Total_Records': total_records,\n",
    "                'Positive_Slopes_Delta_Q_Percentage': positive_percentage_delta_q,\n",
    "                'Mean_R_Squared_Delta_Q': mean_r_squared_delta_q,\n",
    "                'Positive_Slopes_WTE_Percentage': positive_percentage_wte,\n",
    "                'Mean_R_Squared_WTE': mean_r_squared_wte\n",
    "            })\n",
    "\n",
    "            print(f\"{season:12} | Records: {total_records:3d} | Positive Slopes Delta Q: {positive_percentage_delta_q:5.1f}% | Mean R² Delta Q: {mean_r_squared_delta_q:.3f}\")\n",
    "            print(f\"{'':12} | {'':13} | Positive Slopes WTE: {positive_percentage_wte:5.1f}% | Mean R² WTE: {mean_r_squared_wte:.3f}\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "    # Overall statistics\n",
    "    total_all = len(stats_df)\n",
    "    positive_all_delta_q = (stats_df['slope_delta_q'] > 0).sum()\n",
    "    positive_pct_all_delta_q = (positive_all_delta_q / total_all) * 100\n",
    "    mean_r2_all_delta_q = stats_df['r_squared_delta_q'].mean()\n",
    "\n",
    "    positive_all_wte = (stats_df['slope_wte'] > 0).sum()\n",
    "    positive_pct_all_wte = (positive_all_wte / total_all) * 100\n",
    "    mean_r2_all_wte = stats_df['r_squared_wte'].mean()\n",
    "\n",
    "    print(f\"{'OVERALL':12} | Records: {total_all:3d} | Positive Slopes Delta Q: {positive_pct_all_delta_q:5.1f}% | Mean R² Delta Q: {mean_r2_all_delta_q:.3f}\")\n",
    "    print(f\"{'':12} | {'':13} | Positive Slopes WTE: {positive_pct_all_wte:5.1f}% | Mean R² WTE: {mean_r2_all_wte:.3f}\")\n",
    "\n",
    "    # Export to CSV\n",
    "    results_df = pd.DataFrame(seasonal_results)\n",
    "    results_df.to_csv('../reports/figures/seasonal/simple_seasonal_delta_q_wte_report.csv', index=False)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Load seasonal statistics and generate seasonal report\n",
    "seasonal_stats = pd.read_csv('../reports/figures/seasonal/delta_q_delta_wte_seasonal_statistics.csv')\n",
    "simple_seasonal_report = generate_simple_seasonal_report(seasonal_stats)\n"
   ],
   "id": "9a31cfc1441aa2",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../reports/figures/seasonal/delta_q_delta_wte_seasonal_statistics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 83\u001B[39m\n\u001B[32m     80\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m results_df\n\u001B[32m     82\u001B[39m \u001B[38;5;66;03m# Load seasonal statistics and generate seasonal report\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m83\u001B[39m seasonal_stats = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m../reports/figures/seasonal/delta_q_delta_wte_seasonal_statistics.csv\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     84\u001B[39m simple_seasonal_report = generate_simple_seasonal_report(seasonal_stats)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1878\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m   1879\u001B[39m         mode += \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1880\u001B[39m \u001B[38;5;28mself\u001B[39m.handles = \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1881\u001B[39m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1882\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1883\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1884\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcompression\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1885\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmemory_map\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1886\u001B[39m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m=\u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1887\u001B[39m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mencoding_errors\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstrict\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1888\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstorage_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1889\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1890\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1891\u001B[39m f = \u001B[38;5;28mself\u001B[39m.handles.handle\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    874\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    876\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    877\u001B[39m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m=\u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    878\u001B[39m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    879\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: '../reports/figures/seasonal/delta_q_delta_wte_seasonal_statistics.csv'"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9b880e5616bdef3d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
